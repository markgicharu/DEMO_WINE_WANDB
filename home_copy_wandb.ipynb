{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "\r\n",
    "import torch\r\n",
    "import torch.nn as nn\r\n",
    "from torch.nn import functional as F\r\n",
    "\r\n",
    "import torchmetrics\r\n",
    "\r\n",
    "import onnx\r\n",
    "import onnxruntime.quantization\r\n",
    "import onnxruntime\r\n",
    "from onnxruntime.quantization import quantize_qat, quantize_static, QuantType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WANDB LIBRARY\r\n",
    "### IMPORT WANDB AND LOGIN\r\n",
    "Note you may have to login using your API key\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: \"WANDB_NOTEBOOK_NAME\"=\"demo_wine_wandb_test\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Currently logged in as: markgich (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\r\n",
    "%env \"WANDB_NOTEBOOK_NAME\" \"demo_wine_wandb_test\"\r\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./data/wine_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>Alcohol</th>\n",
       "      <th>Malic acid</th>\n",
       "      <th>Ash</th>\n",
       "      <th>Alcalinity of ash</th>\n",
       "      <th>Magnesium</th>\n",
       "      <th>Total phenols</th>\n",
       "      <th>Flavanoids</th>\n",
       "      <th>Nonflavanoid phenols</th>\n",
       "      <th>Proanthocyanins</th>\n",
       "      <th>Color intensity</th>\n",
       "      <th>Hue</th>\n",
       "      <th>OD280/OD315 of diluted wines</th>\n",
       "      <th>Proline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Class  Alcohol  Malic acid   Ash  Alcalinity of ash  Magnesium  \\\n",
       "0      0    14.23        1.71  2.43               15.6        127   \n",
       "1      0    13.20        1.78  2.14               11.2        100   \n",
       "2      0    13.16        2.36  2.67               18.6        101   \n",
       "3      0    14.37        1.95  2.50               16.8        113   \n",
       "4      0    13.24        2.59  2.87               21.0        118   \n",
       "\n",
       "   Total phenols  Flavanoids  Nonflavanoid phenols  Proanthocyanins  \\\n",
       "0           2.80        3.06                  0.28             2.29   \n",
       "1           2.65        2.76                  0.26             1.28   \n",
       "2           2.80        3.24                  0.30             2.81   \n",
       "3           3.85        3.49                  0.24             2.18   \n",
       "4           2.80        2.69                  0.39             1.82   \n",
       "\n",
       "   Color intensity   Hue  OD280/OD315 of diluted wines  Proline  \n",
       "0             5.64  1.04                          3.92     1065  \n",
       "1             4.38  1.05                          3.40     1050  \n",
       "2             5.68  1.03                          3.17     1185  \n",
       "3             7.80  0.86                          3.45     1480  \n",
       "4             4.32  1.04                          2.93      735  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(178, 14)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>Alcohol</th>\n",
       "      <th>Malic acid</th>\n",
       "      <th>Ash</th>\n",
       "      <th>Alcalinity of ash</th>\n",
       "      <th>Magnesium</th>\n",
       "      <th>Total phenols</th>\n",
       "      <th>Flavanoids</th>\n",
       "      <th>Nonflavanoid phenols</th>\n",
       "      <th>Proanthocyanins</th>\n",
       "      <th>Color intensity</th>\n",
       "      <th>Hue</th>\n",
       "      <th>OD280/OD315 of diluted wines</th>\n",
       "      <th>Proline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.938202</td>\n",
       "      <td>13.000618</td>\n",
       "      <td>2.336348</td>\n",
       "      <td>2.366517</td>\n",
       "      <td>19.494944</td>\n",
       "      <td>99.741573</td>\n",
       "      <td>2.295112</td>\n",
       "      <td>2.029270</td>\n",
       "      <td>0.361854</td>\n",
       "      <td>1.590899</td>\n",
       "      <td>5.058090</td>\n",
       "      <td>0.957449</td>\n",
       "      <td>2.611685</td>\n",
       "      <td>746.893258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.775035</td>\n",
       "      <td>0.811827</td>\n",
       "      <td>1.117146</td>\n",
       "      <td>0.274344</td>\n",
       "      <td>3.339564</td>\n",
       "      <td>14.282484</td>\n",
       "      <td>0.625851</td>\n",
       "      <td>0.998859</td>\n",
       "      <td>0.124453</td>\n",
       "      <td>0.572359</td>\n",
       "      <td>2.318286</td>\n",
       "      <td>0.228572</td>\n",
       "      <td>0.709990</td>\n",
       "      <td>314.907474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.030000</td>\n",
       "      <td>0.740000</td>\n",
       "      <td>1.360000</td>\n",
       "      <td>10.600000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.340000</td>\n",
       "      <td>0.130000</td>\n",
       "      <td>0.410000</td>\n",
       "      <td>1.280000</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>1.270000</td>\n",
       "      <td>278.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.362500</td>\n",
       "      <td>1.602500</td>\n",
       "      <td>2.210000</td>\n",
       "      <td>17.200000</td>\n",
       "      <td>88.000000</td>\n",
       "      <td>1.742500</td>\n",
       "      <td>1.205000</td>\n",
       "      <td>0.270000</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>3.220000</td>\n",
       "      <td>0.782500</td>\n",
       "      <td>1.937500</td>\n",
       "      <td>500.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>13.050000</td>\n",
       "      <td>1.865000</td>\n",
       "      <td>2.360000</td>\n",
       "      <td>19.500000</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>2.355000</td>\n",
       "      <td>2.135000</td>\n",
       "      <td>0.340000</td>\n",
       "      <td>1.555000</td>\n",
       "      <td>4.690000</td>\n",
       "      <td>0.965000</td>\n",
       "      <td>2.780000</td>\n",
       "      <td>673.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>13.677500</td>\n",
       "      <td>3.082500</td>\n",
       "      <td>2.557500</td>\n",
       "      <td>21.500000</td>\n",
       "      <td>107.000000</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>2.875000</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>1.950000</td>\n",
       "      <td>6.200000</td>\n",
       "      <td>1.120000</td>\n",
       "      <td>3.170000</td>\n",
       "      <td>985.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>14.830000</td>\n",
       "      <td>5.800000</td>\n",
       "      <td>3.230000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>162.000000</td>\n",
       "      <td>3.880000</td>\n",
       "      <td>5.080000</td>\n",
       "      <td>0.660000</td>\n",
       "      <td>3.580000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>1.710000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1680.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Class     Alcohol  Malic acid         Ash  Alcalinity of ash  \\\n",
       "count  178.000000  178.000000  178.000000  178.000000         178.000000   \n",
       "mean     0.938202   13.000618    2.336348    2.366517          19.494944   \n",
       "std      0.775035    0.811827    1.117146    0.274344           3.339564   \n",
       "min      0.000000   11.030000    0.740000    1.360000          10.600000   \n",
       "25%      0.000000   12.362500    1.602500    2.210000          17.200000   \n",
       "50%      1.000000   13.050000    1.865000    2.360000          19.500000   \n",
       "75%      2.000000   13.677500    3.082500    2.557500          21.500000   \n",
       "max      2.000000   14.830000    5.800000    3.230000          30.000000   \n",
       "\n",
       "        Magnesium  Total phenols  Flavanoids  Nonflavanoid phenols  \\\n",
       "count  178.000000     178.000000  178.000000            178.000000   \n",
       "mean    99.741573       2.295112    2.029270              0.361854   \n",
       "std     14.282484       0.625851    0.998859              0.124453   \n",
       "min     70.000000       0.980000    0.340000              0.130000   \n",
       "25%     88.000000       1.742500    1.205000              0.270000   \n",
       "50%     98.000000       2.355000    2.135000              0.340000   \n",
       "75%    107.000000       2.800000    2.875000              0.437500   \n",
       "max    162.000000       3.880000    5.080000              0.660000   \n",
       "\n",
       "       Proanthocyanins  Color intensity         Hue  \\\n",
       "count       178.000000       178.000000  178.000000   \n",
       "mean          1.590899         5.058090    0.957449   \n",
       "std           0.572359         2.318286    0.228572   \n",
       "min           0.410000         1.280000    0.480000   \n",
       "25%           1.250000         3.220000    0.782500   \n",
       "50%           1.555000         4.690000    0.965000   \n",
       "75%           1.950000         6.200000    1.120000   \n",
       "max           3.580000        13.000000    1.710000   \n",
       "\n",
       "       OD280/OD315 of diluted wines      Proline  \n",
       "count                    178.000000   178.000000  \n",
       "mean                       2.611685   746.893258  \n",
       "std                        0.709990   314.907474  \n",
       "min                        1.270000   278.000000  \n",
       "25%                        1.937500   500.500000  \n",
       "50%                        2.780000   673.500000  \n",
       "75%                        3.170000   985.000000  \n",
       "max                        4.000000  1680.000000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA WRANGLING\r\n",
    "### Check for Nulls and Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Class                           0\n",
       "Alcohol                         0\n",
       "Malic acid                      0\n",
       "Ash                             0\n",
       "Alcalinity of ash               0\n",
       "Magnesium                       0\n",
       "Total phenols                   0\n",
       "Flavanoids                      0\n",
       "Nonflavanoid phenols            0\n",
       "Proanthocyanins                 0\n",
       "Color intensity                 0\n",
       "Hue                             0\n",
       "OD280/OD315 of diluted wines    0\n",
       "Proline                         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MACHINE LEARNING\r\n",
    "### ML PREP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode target labels with value between 0 and n_classes-1.\r\n",
    "# Import Metrics for use with evaluation\r\n",
    "\r\n",
    "from sklearn.preprocessing import LabelEncoder\r\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_curve, roc_auc_score, confusion_matrix\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>Alcohol</th>\n",
       "      <th>Malic acid</th>\n",
       "      <th>Ash</th>\n",
       "      <th>Alcalinity of ash</th>\n",
       "      <th>Magnesium</th>\n",
       "      <th>Total phenols</th>\n",
       "      <th>Flavanoids</th>\n",
       "      <th>Nonflavanoid phenols</th>\n",
       "      <th>Proanthocyanins</th>\n",
       "      <th>Color intensity</th>\n",
       "      <th>Hue</th>\n",
       "      <th>OD280/OD315 of diluted wines</th>\n",
       "      <th>Proline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0</td>\n",
       "      <td>14.10</td>\n",
       "      <td>2.02</td>\n",
       "      <td>2.40</td>\n",
       "      <td>18.8</td>\n",
       "      <td>103</td>\n",
       "      <td>2.75</td>\n",
       "      <td>2.92</td>\n",
       "      <td>0.32</td>\n",
       "      <td>2.38</td>\n",
       "      <td>6.20</td>\n",
       "      <td>1.07</td>\n",
       "      <td>2.75</td>\n",
       "      <td>1060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>1</td>\n",
       "      <td>13.67</td>\n",
       "      <td>1.25</td>\n",
       "      <td>1.92</td>\n",
       "      <td>18.0</td>\n",
       "      <td>94</td>\n",
       "      <td>2.10</td>\n",
       "      <td>1.79</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.73</td>\n",
       "      <td>3.80</td>\n",
       "      <td>1.23</td>\n",
       "      <td>2.46</td>\n",
       "      <td>630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>2</td>\n",
       "      <td>13.11</td>\n",
       "      <td>1.90</td>\n",
       "      <td>2.75</td>\n",
       "      <td>25.5</td>\n",
       "      <td>116</td>\n",
       "      <td>2.20</td>\n",
       "      <td>1.28</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.56</td>\n",
       "      <td>7.10</td>\n",
       "      <td>0.61</td>\n",
       "      <td>1.33</td>\n",
       "      <td>425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>1</td>\n",
       "      <td>11.84</td>\n",
       "      <td>2.89</td>\n",
       "      <td>2.23</td>\n",
       "      <td>18.0</td>\n",
       "      <td>112</td>\n",
       "      <td>1.72</td>\n",
       "      <td>1.32</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.95</td>\n",
       "      <td>2.65</td>\n",
       "      <td>0.96</td>\n",
       "      <td>2.52</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>2</td>\n",
       "      <td>12.53</td>\n",
       "      <td>5.51</td>\n",
       "      <td>2.64</td>\n",
       "      <td>25.0</td>\n",
       "      <td>96</td>\n",
       "      <td>1.79</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.63</td>\n",
       "      <td>1.10</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0.82</td>\n",
       "      <td>1.69</td>\n",
       "      <td>515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>2</td>\n",
       "      <td>12.51</td>\n",
       "      <td>1.24</td>\n",
       "      <td>2.25</td>\n",
       "      <td>17.5</td>\n",
       "      <td>85</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.60</td>\n",
       "      <td>1.25</td>\n",
       "      <td>5.45</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.51</td>\n",
       "      <td>650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>1</td>\n",
       "      <td>12.42</td>\n",
       "      <td>2.55</td>\n",
       "      <td>2.27</td>\n",
       "      <td>22.0</td>\n",
       "      <td>90</td>\n",
       "      <td>1.68</td>\n",
       "      <td>1.84</td>\n",
       "      <td>0.66</td>\n",
       "      <td>1.42</td>\n",
       "      <td>2.70</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.30</td>\n",
       "      <td>315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>2</td>\n",
       "      <td>13.40</td>\n",
       "      <td>4.60</td>\n",
       "      <td>2.86</td>\n",
       "      <td>25.0</td>\n",
       "      <td>112</td>\n",
       "      <td>1.98</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.27</td>\n",
       "      <td>1.11</td>\n",
       "      <td>8.50</td>\n",
       "      <td>0.67</td>\n",
       "      <td>1.92</td>\n",
       "      <td>630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0</td>\n",
       "      <td>13.05</td>\n",
       "      <td>1.77</td>\n",
       "      <td>2.10</td>\n",
       "      <td>17.0</td>\n",
       "      <td>107</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.03</td>\n",
       "      <td>5.04</td>\n",
       "      <td>0.88</td>\n",
       "      <td>3.35</td>\n",
       "      <td>885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>1</td>\n",
       "      <td>11.45</td>\n",
       "      <td>2.40</td>\n",
       "      <td>2.42</td>\n",
       "      <td>20.0</td>\n",
       "      <td>96</td>\n",
       "      <td>2.90</td>\n",
       "      <td>2.79</td>\n",
       "      <td>0.32</td>\n",
       "      <td>1.83</td>\n",
       "      <td>3.25</td>\n",
       "      <td>0.80</td>\n",
       "      <td>3.39</td>\n",
       "      <td>625</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Class  Alcohol  Malic acid   Ash  Alcalinity of ash  Magnesium  \\\n",
       "48       0    14.10        2.02  2.40               18.8        103   \n",
       "62       1    13.67        1.25  1.92               18.0         94   \n",
       "152      2    13.11        1.90  2.75               25.5        116   \n",
       "77       1    11.84        2.89  2.23               18.0        112   \n",
       "137      2    12.53        5.51  2.64               25.0         96   \n",
       "134      2    12.51        1.24  2.25               17.5         85   \n",
       "105      1    12.42        2.55  2.27               22.0         90   \n",
       "169      2    13.40        4.60  2.86               25.0        112   \n",
       "44       0    13.05        1.77  2.10               17.0        107   \n",
       "120      1    11.45        2.40  2.42               20.0         96   \n",
       "\n",
       "     Total phenols  Flavanoids  Nonflavanoid phenols  Proanthocyanins  \\\n",
       "48            2.75        2.92                  0.32             2.38   \n",
       "62            2.10        1.79                  0.32             0.73   \n",
       "152           2.20        1.28                  0.26             1.56   \n",
       "77            1.72        1.32                  0.43             0.95   \n",
       "137           1.79        0.60                  0.63             1.10   \n",
       "134           2.00        0.58                  0.60             1.25   \n",
       "105           1.68        1.84                  0.66             1.42   \n",
       "169           1.98        0.96                  0.27             1.11   \n",
       "44            3.00        3.00                  0.28             2.03   \n",
       "120           2.90        2.79                  0.32             1.83   \n",
       "\n",
       "     Color intensity   Hue  OD280/OD315 of diluted wines  Proline  \n",
       "48              6.20  1.07                          2.75     1060  \n",
       "62              3.80  1.23                          2.46      630  \n",
       "152             7.10  0.61                          1.33      425  \n",
       "77              2.65  0.96                          2.52      500  \n",
       "137             5.00  0.82                          1.69      515  \n",
       "134             5.45  0.75                          1.51      650  \n",
       "105             2.70  0.86                          3.30      315  \n",
       "169             8.50  0.67                          1.92      630  \n",
       "44              5.04  0.88                          3.35      885  \n",
       "120             3.25  0.80                          3.39      625  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = LabelEncoder()\r\n",
    "df['Class'] = le.fit_transform(df['Class'])\r\n",
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2], dtype=int64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Class'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SEPARATE FEATURES AND TARGET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Alcohol</th>\n",
       "      <th>Malic acid</th>\n",
       "      <th>Ash</th>\n",
       "      <th>Alcalinity of ash</th>\n",
       "      <th>Magnesium</th>\n",
       "      <th>Total phenols</th>\n",
       "      <th>Flavanoids</th>\n",
       "      <th>Nonflavanoid phenols</th>\n",
       "      <th>Proanthocyanins</th>\n",
       "      <th>Color intensity</th>\n",
       "      <th>Hue</th>\n",
       "      <th>OD280/OD315 of diluted wines</th>\n",
       "      <th>Proline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Alcohol  Malic acid   Ash  Alcalinity of ash  Magnesium  Total phenols  \\\n",
       "0    14.23        1.71  2.43               15.6        127           2.80   \n",
       "1    13.20        1.78  2.14               11.2        100           2.65   \n",
       "2    13.16        2.36  2.67               18.6        101           2.80   \n",
       "3    14.37        1.95  2.50               16.8        113           3.85   \n",
       "4    13.24        2.59  2.87               21.0        118           2.80   \n",
       "\n",
       "   Flavanoids  Nonflavanoid phenols  Proanthocyanins  Color intensity   Hue  \\\n",
       "0        3.06                  0.28             2.29             5.64  1.04   \n",
       "1        2.76                  0.26             1.28             4.38  1.05   \n",
       "2        3.24                  0.30             2.81             5.68  1.03   \n",
       "3        3.49                  0.24             2.18             7.80  0.86   \n",
       "4        2.69                  0.39             1.82             4.32  1.04   \n",
       "\n",
       "   OD280/OD315 of diluted wines  Proline  \n",
       "0                          3.92     1065  \n",
       "1                          3.40     1050  \n",
       "2                          3.17     1185  \n",
       "3                          3.45     1480  \n",
       "4                          2.93      735  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set the feature variables\r\n",
    "\r\n",
    "df_features = df.drop('Class', axis=1)\r\n",
    "df_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Class\n",
       "0      0\n",
       "1      0\n",
       "2      0\n",
       "3      0\n",
       "4      0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set the target variable\r\n",
    "\r\n",
    "df_target = df[['Class']]\r\n",
    "df_target.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset in train and test with a ratio of 70-30\r\n",
    "\r\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, x_test, Y_train, y_test = train_test_split(df_features, \r\n",
    "                                                    df_target,\r\n",
    "                                                    test_size=0.3,\r\n",
    "                                                     random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((124, 13), (54, 13))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, x_test.shape,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((124, 1), (54, 1))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert data to Tensors for Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([124, 13]) torch.Size([54, 13])\n"
     ]
    }
   ],
   "source": [
    "Xtrain = torch.from_numpy(X_train.values).float()\r\n",
    "Xtest = torch.from_numpy(x_test.values).float()\r\n",
    "print(Xtrain.shape, Xtest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32 torch.float32\n"
     ]
    }
   ],
   "source": [
    "print(Xtrain.dtype, Xtest.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have successfully converted our  X_data into torch tensors of float32 datatype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([124]) torch.Size([54])\n",
      "torch.int64 torch.int64\n"
     ]
    }
   ],
   "source": [
    "# Reshape tensor to 1D\r\n",
    "\r\n",
    "Ytrain = torch.from_numpy(Y_train.values).view(1,-1)[0]\r\n",
    "Ytest = torch.from_numpy(y_test.values).view(1, -1)[0]\r\n",
    "print(Ytrain.shape, Ytest.shape)\r\n",
    "print(Ytrain.dtype, Ytest.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the **view()** to reshape the tensor.<br>\r\n",
    "The loss function doesn't support multi-target and therefore, we should use a 1D Tensor of 1 row containing the labels.<br>\r\n",
    "We have successfully converted our y_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.int64 torch.int64\n"
     ]
    }
   ],
   "source": [
    "print(Ytrain.dtype, Ytest.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch\r\n",
    "### We create a classifier and define our neural network for our model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 13\r\n",
    "output_size = 3\r\n",
    "hidden_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = dict(\r\n",
    "                dataset = \"wine dataset\",\r\n",
    "                architecture = 'Linear', \r\n",
    "                learning_rate = 0.01,\r\n",
    "                loss = nn.NLLLoss(),\r\n",
    "                optimizer = \"adam\",\r\n",
    ")\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset wine dataset\n",
      "architecture Linear\n",
      "learning_rate 0.01\n",
      "loss NLLLoss()\n",
      "optimizer adam\n"
     ]
    }
   ],
   "source": [
    "for k,v in config.items():\r\n",
    "    print(k, v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the neural network\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "class Net(nn.Module):\r\n",
    "    \r\n",
    "    def __init__(self):\r\n",
    "        super(Net, self).__init__()\r\n",
    "        self.fc1 = nn.Linear(config.get(\"input_size\"), config.get(\"hidden_size\"))\r\n",
    "        self.fc2 = nn.Linear(config.get(\"input_size\"), config.get(\"hidden_size\"))\r\n",
    "        self.fc3 = nn.Linear(config.get(\"input_size\"), config.get(\"output_size\"))\r\n",
    "\r\n",
    "    def forward(self, X):\r\n",
    "        X = torch.sigmoid((self.fc1(X)))\r\n",
    "        X = torch.sigmoid(self.fc2(X))\r\n",
    "        X = self.fc3(X)\r\n",
    "\r\n",
    "        return F.log_softmax(X, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\r\n",
    "    \r\n",
    "    def __init__(self):\r\n",
    "        super(Net, self).__init__()\r\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\r\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size)\r\n",
    "        self.fc3 = nn.Linear(hidden_size, output_size)\r\n",
    "\r\n",
    "        self.dropout = nn.Dropout(0.25)\r\n",
    "\r\n",
    "\r\n",
    "    def forward(self, X):\r\n",
    "        X = torch.sigmoid((self.fc1(X)))\r\n",
    "        X = self.dropout(X)\r\n",
    "        X = torch.sigmoid(self.fc2(X))\r\n",
    "        X = self.dropout(X)\r\n",
    "        X = self.fc3(X)\r\n",
    "\r\n",
    "        return F.log_softmax(X, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (fc1): Linear(in_features=13, out_features=100, bias=True)\n",
       "  (fc2): Linear(in_features=100, out_features=100, bias=True)\n",
       "  (fc3): Linear(in_features=100, out_features=3, bias=True)\n",
       "  (dropout): Dropout(p=0.25, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# instantiate model\r\n",
    "model = Net()\r\n",
    "# move model to gpu\r\n",
    "#model.to(device)\r\n",
    "# preview our model\r\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Optimizer and Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#optimizer = optim.Adam(model.parameters(), lr=config.get(\"learning_rate\"))\r\n",
    "loss_fn = config.get(\"loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the optimizer\r\n",
    "\r\n",
    "if config.get(\"optimizer\")=='sgd':\r\n",
    "    optimizer = optim.SGD(model.parameters(),lr=config.get(\"learning_rate\"), momentum=0.9)\r\n",
    "elif config.get(\"optimizer\")=='adam':\r\n",
    "    optimizer = optim.Adam(model.parameters(),lr=config.get(\"learning_rate\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Loss\r\n",
    "\r\n",
    "if config.get(\"loss\") == \"NLLLoss\":\r\n",
    "    loss_fn = nn.NLLLoss()\r\n",
    "elif config.get(\"loss\") == \"CrossEntropyLoss\":\r\n",
    "    loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAIN AND LOG THE MODEL\r\n",
    "### Train the Model for 1000 Epochs\r\n",
    "### Log the model Parameters\r\n",
    "### Export Model, Import and Set to Eval\r\n",
    "### Log Metrics on Model.Eval\r\n",
    "### Convert and Export to ONNX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAIN THE MODEL\r\n",
    "\r\n",
    "\r\n",
    "epochs = 1000\r\n",
    "with wandb.init(project=\"demo_wandb_test\", config = config):\r\n",
    "    wandb.watch(model, criterion=None, log=\"all\", log_freq=10)\r\n",
    "    \r\n",
    "    for epoch in range(epochs):\r\n",
    "        # zero the gradients\r\n",
    "        optimizer.zero_grad()\r\n",
    "        # train the model\r\n",
    "        Ypred = model(Xtrain)\r\n",
    "        # compute the accuract\r\n",
    "        acc = torchmetrics.functional.accuracy(Ypred, Ytrain)\r\n",
    "        # compute the loss\r\n",
    "        loss = loss_fn(Ypred, Ytrain)\r\n",
    "        # update the model weights\r\n",
    "        loss.backward()\r\n",
    "        # optimize the learning parameters and step forward\r\n",
    "        optimizer.step()\r\n",
    "        # log the metrics\r\n",
    "        wandb.log({'Epoch': epoch, \"Loss\": loss.item(), \"Accuracy\": acc})\r\n",
    "\r\n",
    "\r\n",
    "    # SAVE MODEL STATE DICT TO DISK\r\n",
    "\r\n",
    "    wandb.save(torch.save(model.state_dict(), \"./models/home_state_dict.pt\"))\r\n",
    "\r\n",
    "    # LOAD MODEL FROM DISK and EVALUATE\r\n",
    "\r\n",
    "    new_model =  Net()\r\n",
    "    new_model.load_state_dict(torch.load(\"./models/home_state_dict.pt\"))\r\n",
    "    new_model.eval()\r\n",
    "\r\n",
    "    # SET THE PREDICTIONS\r\n",
    "\r\n",
    "    predict = new_model(Xtest)\r\n",
    "    _, predict_y = torch.max(predict, 1)\r\n",
    "\r\n",
    "\r\n",
    "    # VISUALIZE CONFUSION MATRIX\r\n",
    "    wandb.sklearn.plot_confusion_matrix(Ytest, predict_y, labels = [0,1,2])\r\n",
    "\r\n",
    "    # Print Metrics\r\n",
    "\r\n",
    "    wandb.log({\"accuracy_score\" : accuracy_score(Ytest, predict_y),\r\n",
    "    \"precision_score\" : precision_score(Ytest, predict_y, average='weighted'),\r\n",
    "    \"recall_score\": recall_score(Ytest, predict_y, average=\"weighted\"),\r\n",
    "    \r\n",
    "    })\r\n",
    "    \r\n",
    "    torch.onnx.export(model = model,args =  (Xtrain), f = \"./models/home_state_test.onnx\", input_names=['input'], output_names = ['output'],\r\n",
    "    verbose=True, do_constant_folding=True, opset_version=11)\r\n",
    "wandb.finish()\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMPUTE METRICS ON EACH RUN\r\n",
    "## TRAIN AND EVALUATE LOOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN THE MODEL\r\n",
    "def train():\r\n",
    "    epochs = 1000\r\n",
    "    accuracy = 0\r\n",
    "    with wandb.init(project=\"demo_wandb_test\", config = config):\r\n",
    "        wandb.watch(model, criterion=None, log=\"all\", log_freq=10)\r\n",
    "        # train\r\n",
    "        for epoch in range(epochs):\r\n",
    "            # zero the gradients\r\n",
    "            optimizer.zero_grad()\r\n",
    "            # train the model and get an output\r\n",
    "            Ypred = model(Xtrain)\r\n",
    "            # compute the accuracy\r\n",
    "            acc = torchmetrics.functional.accuracy(Ypred, Ytrain)\r\n",
    "            accuracy += int(sum(Ypred == Ytest))\r\n",
    "            # compute the loss\r\n",
    "            loss = loss_fn(Ypred, Ytrain)\r\n",
    "            # update the model weights\r\n",
    "            loss.backward()\r\n",
    "            # optimize the learning parameters and step forward\r\n",
    "            optimizer.step()\r\n",
    "            # log the metrics\r\n",
    "            wandb.log({'Epoch': epoch, \"Train Loss\": loss.item(), \"Torch Accuracy\": acc, \"Train Accuracy\":accuracy})\r\n",
    "\r\n",
    "\r\n",
    "        # SAVE MODEL STATE DICT TO DISK\r\n",
    "\r\n",
    "        wandb.save(torch.save(model.state_dict(), \"./models/home_state_dict.pt\"))\r\n",
    "\r\n",
    "        # EVALUATE\r\n",
    "        # LOAD MODEL FROM DISK and EVALUATE\r\n",
    "\r\n",
    "\r\n",
    "        new_model =  Net()\r\n",
    "        new_model.load_state_dict(torch.load(\"./models/home_state_dict.pt\"))\r\n",
    "        new_model.eval()\r\n",
    "\r\n",
    "        # SET THE PREDICTIONS\r\n",
    "\r\n",
    "        predict = new_model(Xtest)\r\n",
    "        _, predict_y = torch.max(predict, 1)\r\n",
    "\r\n",
    "\r\n",
    "        # VISUALIZE CONFUSION MATRIX\r\n",
    "        wandb.sklearn.plot_confusion_matrix(Ytest, predict_y, labels = [0,1,2])\r\n",
    "\r\n",
    "        # Print Metrics\r\n",
    "\r\n",
    "        wandb.log({\"accuracy_score\" : accuracy_score(Ytest, predict_y),\r\n",
    "        \"precision_score\" : precision_score(Ytest, predict_y, average='weighted'),\r\n",
    "        \"recall_score\": recall_score(Ytest, predict_y, average=\"weighted\"),\r\n",
    "        \r\n",
    "        })\r\n",
    "        \r\n",
    "        torch.onnx.export(model = model,args =  (Xtrain), f = \"./models/home_state_test.onnx\", input_names=['input'], output_names = ['output'],\r\n",
    "        verbose=True, do_constant_folding=True, opset_version=11)\r\n",
    "    wandb.finish()\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.33<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">genial-lion-40</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/markgich/demo_wandb_test\" target=\"_blank\">https://wandb.ai/markgich/demo_wandb_test</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/markgich/demo_wandb_test/runs/fpmpu5hx\" target=\"_blank\">https://wandb.ai/markgich/demo_wandb_test/runs/fpmpu5hx</a><br/>\n",
       "                Run data is saved locally in <code>c:\\Users\\markg\\Documents\\PROGRAMMING\\PYTHON_PROJECTS\\TORCH\\DEMO_WINE_WANDB\\wandb\\run-20210710_001725-fpmpu5hx</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 38656<br/>Program failed with code 1.  Press ctrl-c to abort syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f25f4a1543f1444cbaa451439ece41b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>c:\\Users\\markg\\Documents\\PROGRAMMING\\PYTHON_PROJECTS\\TORCH\\DEMO_WINE_WANDB\\wandb\\run-20210710_001725-fpmpu5hx\\logs\\debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>c:\\Users\\markg\\Documents\\PROGRAMMING\\PYTHON_PROJECTS\\TORCH\\DEMO_WINE_WANDB\\wandb\\run-20210710_001725-fpmpu5hx\\logs\\debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 4 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">genial-lion-40</strong>: <a href=\"https://wandb.ai/markgich/demo_wandb_test/runs/fpmpu5hx\" target=\"_blank\">https://wandb.ai/markgich/demo_wandb_test/runs/fpmpu5hx</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (3) must match the size of tensor b (54) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-2da0ffaf5447>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-32-bcdbf3cc426a>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     13\u001b[0m             \u001b[1;31m# compute the accuracy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m             \u001b[0macc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorchmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mYpred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mYtrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m             \u001b[0maccuracy\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mYpred\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mYtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m             \u001b[1;31m# compute the loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mYpred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mYtrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: The size of tensor a (3) must match the size of tensor b (54) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OPTIMIZE NETWORK WITH SWEEPS\r\n",
    "### WANDB SWEEPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace agent with own agent line generated from project\r\n",
    "!wandb agent markgich/demo_wandb_test/izsvluxh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep_config = {\r\n",
    "    'method': 'grid', #grid, random\r\n",
    "    'metric': {\r\n",
    "      'name': 'loss',\r\n",
    "      'goal': 'minimize'   \r\n",
    "    },\r\n",
    "    'parameters': {\r\n",
    "        'epochs': {\r\n",
    "            'values': [100, 500, 1000]\r\n",
    "        },\r\n",
    "        \r\n",
    "        'learning_rate': {\r\n",
    "            'values': [1e-2, 1e-3, 1e-4, 3e-4, 3e-5, 1e-5]\r\n",
    "        },\r\n",
    "        'fc_layer_size':{\r\n",
    "            'values':[128,256,512]\r\n",
    "        },\r\n",
    "        'optimizer': {\r\n",
    "            'values': ['adam', 'sgd']\r\n",
    "        },\r\n",
    "        'loss':{\r\n",
    "            'values':[\"NLLLoss\", \"CategoricalCrossEntropy\"]\r\n",
    "        }\r\n",
    "    }\r\n",
    "}\r\n",
    "sweep_id = wandb.sweep(sweep_config)\r\n",
    "#wandb.agent(sweep_id=sweep_id, project=\"demo_wandb_test\", )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ADD HYPERPARAMETER TUNING SWEEPS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEMO OF IT\r\n",
    "def train():\r\n",
    "    with wandb.init() as run:\r\n",
    "        config = wandb.config\r\n",
    "        model = Model(config)\r\n",
    "        for epoch in range(config[\"epochs\"]):\r\n",
    "            loss = model.fit()  # your model training code here\r\n",
    "            wandb.log({\"loss\": loss, \"epoch\": epoch})\r\n",
    "\r\n",
    "count = 5 # number of runs to execute\r\n",
    "wandb.agent(sweep_id, function=train, count=count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\r\n",
    "def train():\r\n",
    "    # TRAIN THE MODEL\r\n",
    "    epochs = 1000\r\n",
    "    with wandb.init(project=\"demo_wandb_test\", config = config):\r\n",
    "        #wandb.watch(model, criterion=None, log=\"gradients\", log_freq=10)\r\n",
    "        \r\n",
    "        for epoch in range(epochs):\r\n",
    "            # zero the gradients\r\n",
    "            optimizer.zero_grad()\r\n",
    "            # train the model\r\n",
    "            Ypred = model(Xtrain)\r\n",
    "            # compute the accuract\r\n",
    "            acc = torchmetrics.functional.accuracy(Ypred, Ytrain)\r\n",
    "            # compute the loss\r\n",
    "            loss = loss_fn(Ypred, Ytrain)\r\n",
    "            # update the model weights\r\n",
    "            loss.backward()\r\n",
    "            # optimize the learning parameters and step forward\r\n",
    "            optimizer.step()\r\n",
    "            # log the metrics\r\n",
    "            wandb.log({'Epoch': epoch, \"Loss\": loss.item(), \"Accuracy\": acc})\r\n",
    "\r\n",
    "\r\n",
    "        # SAVE MODEL STATE DICT TO DISK\r\n",
    "\r\n",
    "        wandb.save(torch.save(model.state_dict(), \"./models/home_state_dict.pt\"))\r\n",
    "\r\n",
    "        # LOAD MODEL FROM DISK and EVALUATE\r\n",
    "\r\n",
    "        new_model =  Net()\r\n",
    "        new_model.load_state_dict(torch.load(\"./models/home_state_dict.pt\"))\r\n",
    "        new_model.eval()\r\n",
    "\r\n",
    "        # SET THE PREDICTIONS\r\n",
    "\r\n",
    "        predict = new_model(Xtest)\r\n",
    "        _, predict_y = torch.max(predict, 1)\r\n",
    "\r\n",
    "\r\n",
    "        # VISUALIZE CONFUSION MATRIX\r\n",
    "        wandb.sklearn.plot_confusion_matrix(Ytest, predict_y, labels = [0,1,2])\r\n",
    "\r\n",
    "        # Print Metrics\r\n",
    "\r\n",
    "        wandb.log({\"accuracy_score\" : accuracy_score(Ytest, predict_y),\r\n",
    "        \"precision_score\" : precision_score(Ytest, predict_y, average='weighted'),\r\n",
    "        \"recall_score\": recall_score(Ytest, predict_y, average=\"weighted\"),\r\n",
    "        \r\n",
    "        })\r\n",
    "        \r\n",
    "        torch.onnx.export(model = model,args =  (Xtrain), f = \"./models/home_state_test.onnx\", input_names=['input'], output_names = ['output'],\r\n",
    "        verbose=True, do_constant_folding=True, opset_version=11)\r\n",
    "    wandb.finish()\r\n",
    "\r\n",
    "count = 5 # number of runs to execute\r\n",
    "wandb.agent(sweep_id = sweep_id, project=\"demo_wandb_test\", function=train(), count=count)\r\n",
    "#wandb.agent(sweep_id=sweep_id, project=\"demo_wandb_test\", )"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "778de6fd147bda85163a324ce7339acfc1c656b45f8b8593316159881a238432"
  },
  "kernelspec": {
   "display_name": "Python 3.8.6 64-bit ('torch-venv': venv)",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": ""
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}