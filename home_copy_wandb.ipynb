{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "\r\n",
    "import torch\r\n",
    "import torch.nn as nn\r\n",
    "from torch.nn import functional as F\r\n",
    "\r\n",
    "import torchmetrics\r\n",
    "\r\n",
    "import onnx\r\n",
    "import onnxruntime.quantization\r\n",
    "import onnxruntime\r\n",
    "from onnxruntime.quantization import quantize_qat, quantize_static, QuantType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WANDB LIBRARY\r\n",
    "### IMPORT WANDB AND LOGIN\r\n",
    "Note you may have to login using your API key\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\r\n",
    "%env \"WANDB_NOTEBOOK_NAME\" \"demo_wine_wandb_test\"\r\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./data/wine_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA WRANGLING\r\n",
    "### Check for Nulls and Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MACHINE LEARNING\r\n",
    "### ML PREP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode target labels with value between 0 and n_classes-1.\r\n",
    "# Import Metrics for use with evaluation\r\n",
    "\r\n",
    "from sklearn.preprocessing import LabelEncoder\r\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_curve, roc_auc_score, confusion_matrix\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\r\n",
    "df['Class'] = le.fit_transform(df['Class'])\r\n",
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Class'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SEPARATE FEATURES AND TARGET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the feature variables\r\n",
    "\r\n",
    "df_features = df.drop('Class', axis=1)\r\n",
    "df_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the target variable\r\n",
    "\r\n",
    "df_target = df[['Class']]\r\n",
    "df_target.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset in train and test with a ratio of 70-30\r\n",
    "\r\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, x_test, Y_train, y_test = train_test_split(df_features, \r\n",
    "                                                    df_target,\r\n",
    "                                                    test_size=0.3,\r\n",
    "                                                     random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, x_test.shape,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert data to Tensors for Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain = torch.from_numpy(X_train.values).float()\r\n",
    "Xtest = torch.from_numpy(x_test.values).float()\r\n",
    "print(Xtrain.shape, Xtest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Xtrain.dtype, Xtest.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have successfully converted our  X_data into torch tensors of float32 datatype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape tensor to 1D\r\n",
    "\r\n",
    "Ytrain = torch.from_numpy(Y_train.values).view(1,-1)[0]\r\n",
    "Ytest = torch.from_numpy(y_test.values).view(1, -1)[0]\r\n",
    "print(Ytrain.shape, Ytest.shape)\r\n",
    "print(Ytrain.dtype, Ytest.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the **view()** to reshape the tensor.<br>\r\n",
    "The loss function doesn't support multi-target and therefore, we should use a 1D Tensor of 1 row containing the labels.<br>\r\n",
    "We have successfully converted our y_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Ytrain.dtype, Ytest.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch\r\n",
    "### We create a classifier and define our neural network for our model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 13\r\n",
    "output_size = 3\r\n",
    "hidden_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = dict(\r\n",
    "                dataset = \"wine dataset\",\r\n",
    "                architecture = 'Linear', \r\n",
    "                learning_rate = 0.01,\r\n",
    "                loss = nn.NLLLoss(),\r\n",
    "                optimizer = \"adam\",\r\n",
    ")\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,v in config.items():\r\n",
    "    print(k, v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the neural network\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "class Net(nn.Module):\r\n",
    "    \r\n",
    "    def __init__(self):\r\n",
    "        super(Net, self).__init__()\r\n",
    "        self.fc1 = nn.Linear(config.get(\"input_size\"), config.get(\"hidden_size\"))\r\n",
    "        self.fc2 = nn.Linear(config.get(\"input_size\"), config.get(\"hidden_size\"))\r\n",
    "        self.fc3 = nn.Linear(config.get(\"input_size\"), config.get(\"output_size\"))\r\n",
    "\r\n",
    "    def forward(self, X):\r\n",
    "        X = torch.sigmoid((self.fc1(X)))\r\n",
    "        X = torch.sigmoid(self.fc2(X))\r\n",
    "        X = self.fc3(X)\r\n",
    "\r\n",
    "        return F.log_softmax(X, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\r\n",
    "    \r\n",
    "    def __init__(self):\r\n",
    "        super(Net, self).__init__()\r\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\r\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size)\r\n",
    "        self.fc3 = nn.Linear(hidden_size, output_size)\r\n",
    "\r\n",
    "    def forward(self, X):\r\n",
    "        X = torch.sigmoid((self.fc1(X)))\r\n",
    "        X = torch.sigmoid(self.fc2(X))\r\n",
    "        X = self.fc3(X)\r\n",
    "\r\n",
    "        return F.log_softmax(X, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate model\r\n",
    "model = Net()\r\n",
    "# move model to gpu\r\n",
    "#model.to(device)\r\n",
    "# preview our model\r\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Optimizer and Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#optimizer = optim.Adam(model.parameters(), lr=config.get(\"learning_rate\"))\r\n",
    "loss_fn = config.get(\"loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the optimizer\r\n",
    "\r\n",
    "if config.get(\"optimizer\")=='sgd':\r\n",
    "    optimizer = optim.SGD(model.parameters(),lr=config.get(\"learning_rate\"), momentum=0.9)\r\n",
    "elif config.get(\"optimizer\")=='adam':\r\n",
    "    optimizer = optim.Adam(model.parameters(),lr=config.get(\"learning_rate\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Loss\r\n",
    "\r\n",
    "if config.get(\"loss\") == \"NLLLoss\":\r\n",
    "    loss_fn = nn.NLLLoss()\r\n",
    "elif config.get(\"loss\") == \"CrossEntropyLoss\":\r\n",
    "    loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAIN AND LOG THE MODEL\r\n",
    "### Train the Model for 1000 Epochs\r\n",
    "### Log the model Parameters\r\n",
    "### Export Model, Import and Set to Eval\r\n",
    "### Log Metrics on Model.Eval\r\n",
    "### Convert and Export to ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN THE MODEL\r\n",
    "#acc = torchmetrics.Accuracy()\r\n",
    "\r\n",
    "epochs = 1000\r\n",
    "with wandb.init(project=\"demo_wandb_test\", config = config):\r\n",
    "    wandb.watch(model, criterion=None, log=\"gradients\", log_freq=10)\r\n",
    "    \r\n",
    "    for epoch in range(epochs):\r\n",
    "        # zero the gradients\r\n",
    "        optimizer.zero_grad()\r\n",
    "        # train the model\r\n",
    "        Ypred = model(Xtrain)\r\n",
    "        # compute the accuract\r\n",
    "        acc = torchmetrics.functional.accuracy(Ypred, Ytrain)\r\n",
    "        # compute the loss\r\n",
    "        loss = loss_fn(Ypred, Ytrain)\r\n",
    "        # update the model weights\r\n",
    "        loss.backward()\r\n",
    "        # optimize the learning parameters and step forward\r\n",
    "        optimizer.step()\r\n",
    "        # log the metrics\r\n",
    "        wandb.log({'Epoch': epoch, \"Loss\": loss.item(), \"Accuracy\": acc})\r\n",
    "\r\n",
    "\r\n",
    "    # SAVE MODEL STATE DICT TO DISK\r\n",
    "\r\n",
    "    wandb.save(torch.save(model.state_dict(), \"./models/home_state_dict.pt\"))\r\n",
    "\r\n",
    "    # LOAD MODEL FROM DISK and EVALUATE\r\n",
    "\r\n",
    "    new_model =  Net()\r\n",
    "    new_model.load_state_dict(torch.load(\"./models/home_state_dict.pt\"))\r\n",
    "    new_model.eval()\r\n",
    "\r\n",
    "    # SET THE PREDICTIONS\r\n",
    "\r\n",
    "    predict = new_model(Xtest)\r\n",
    "    _, predict_y = torch.max(predict, 1)\r\n",
    "    ground = Ypred.detach().numpy()\r\n",
    "\r\n",
    "    # VISUALIZE CONFUSION MATRIX\r\n",
    "\r\n",
    "    wandb.sklearn.plot_confusion_matrix(Ytest, predict_y, labels = [0,1,2])\r\n",
    "    #wandb.plot.roc_curve(Ytest, ground, labels=[0,1,2])\r\n",
    "    #wandb.plot.roc_curve(predict_y, Ytest)\r\n",
    "    # Print Metrics\r\n",
    "\r\n",
    "    wandb.log({\"accuracy_score\" : accuracy_score(Ytest, predict_y),\r\n",
    "    \"precision_score\" : precision_score(Ytest, predict_y, average='weighted'),\r\n",
    "    \"recall_score\": recall_score(Ytest, predict_y, average=\"weighted\"),\r\n",
    "    #\"roc_curve\": roc_curve(Ytest, predict_y,),\r\n",
    "    \"roc_auc_score\": roc_auc_score(Ytest, predict_y, average=\"macro\",  multi_class='ovr'), \r\n",
    "    \r\n",
    "    })\r\n",
    "    \r\n",
    "    torch.onnx.export(model = model,args =  (Xtrain), f = \"./models/home_state_test.onnx\", input_names=['input'], output_names = ['output'],\r\n",
    "    verbose=True, do_constant_folding=True, opset_version=11)\r\n",
    "wandb.finish()\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OPTIMIZE NETWORK WITH SWEEPS\r\n",
    "### WANDB SWEEPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace agent with own agent line generated from project\r\n",
    "!wandb agent markgich/demo_wandb_test/izsvluxh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep_config = {\r\n",
    "    'method': 'random', #grid, random\r\n",
    "    'metric': {\r\n",
    "      'name': 'loss',\r\n",
    "      'goal': 'minimize'   \r\n",
    "    },\r\n",
    "    'parameters': {\r\n",
    "        'epochs': {\r\n",
    "            'values': [100, 500, 1000]\r\n",
    "        },\r\n",
    "        \r\n",
    "        'learning_rate': {\r\n",
    "            'values': [1e-2, 1e-3, 1e-4, 3e-4, 3e-5, 1e-5]\r\n",
    "        },\r\n",
    "        'fc_layer_size':{\r\n",
    "            'values':[128,256,512]\r\n",
    "        },\r\n",
    "        'optimizer': {\r\n",
    "            'values': ['adam', 'sgd']\r\n",
    "        },\r\n",
    "    }\r\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ADD HYPERPARAMETER TUNING SWEEPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEMO OF IT"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "778de6fd147bda85163a324ce7339acfc1c656b45f8b8593316159881a238432"
  },
  "kernelspec": {
   "display_name": "Python 3.8.6 64-bit ('torch-venv': venv)",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": ""
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}