{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "\r\n",
    "import torch\r\n",
    "import torch.nn as nn\r\n",
    "from torch.nn import functional as F\r\n",
    "\r\n",
    "import torchmetrics\r\n",
    "\r\n",
    "import onnx\r\n",
    "import onnxruntime.quantization\r\n",
    "import onnxruntime\r\n",
    "from onnxruntime.quantization import quantize_qat, quantize_static, QuantType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WANDB LIBRARY\r\n",
    "### IMPORT WANDB AND LOGIN\r\n",
    "Note you may have to login using your API key\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: \"WANDB_NOTEBOOK_NAME\"=\"demo_wine_wandb_test\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Currently logged in as: markgich (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\r\n",
    "%env \"WANDB_NOTEBOOK_NAME\" \"demo_wine_wandb_test\"\r\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./data/wine_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>Alcohol</th>\n",
       "      <th>Malic acid</th>\n",
       "      <th>Ash</th>\n",
       "      <th>Alcalinity of ash</th>\n",
       "      <th>Magnesium</th>\n",
       "      <th>Total phenols</th>\n",
       "      <th>Flavanoids</th>\n",
       "      <th>Nonflavanoid phenols</th>\n",
       "      <th>Proanthocyanins</th>\n",
       "      <th>Color intensity</th>\n",
       "      <th>Hue</th>\n",
       "      <th>OD280/OD315 of diluted wines</th>\n",
       "      <th>Proline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Class  Alcohol  Malic acid   Ash  Alcalinity of ash  Magnesium  \\\n",
       "0      0    14.23        1.71  2.43               15.6        127   \n",
       "1      0    13.20        1.78  2.14               11.2        100   \n",
       "2      0    13.16        2.36  2.67               18.6        101   \n",
       "3      0    14.37        1.95  2.50               16.8        113   \n",
       "4      0    13.24        2.59  2.87               21.0        118   \n",
       "\n",
       "   Total phenols  Flavanoids  Nonflavanoid phenols  Proanthocyanins  \\\n",
       "0           2.80        3.06                  0.28             2.29   \n",
       "1           2.65        2.76                  0.26             1.28   \n",
       "2           2.80        3.24                  0.30             2.81   \n",
       "3           3.85        3.49                  0.24             2.18   \n",
       "4           2.80        2.69                  0.39             1.82   \n",
       "\n",
       "   Color intensity   Hue  OD280/OD315 of diluted wines  Proline  \n",
       "0             5.64  1.04                          3.92     1065  \n",
       "1             4.38  1.05                          3.40     1050  \n",
       "2             5.68  1.03                          3.17     1185  \n",
       "3             7.80  0.86                          3.45     1480  \n",
       "4             4.32  1.04                          2.93      735  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(178, 14)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>Alcohol</th>\n",
       "      <th>Malic acid</th>\n",
       "      <th>Ash</th>\n",
       "      <th>Alcalinity of ash</th>\n",
       "      <th>Magnesium</th>\n",
       "      <th>Total phenols</th>\n",
       "      <th>Flavanoids</th>\n",
       "      <th>Nonflavanoid phenols</th>\n",
       "      <th>Proanthocyanins</th>\n",
       "      <th>Color intensity</th>\n",
       "      <th>Hue</th>\n",
       "      <th>OD280/OD315 of diluted wines</th>\n",
       "      <th>Proline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.938202</td>\n",
       "      <td>13.000618</td>\n",
       "      <td>2.336348</td>\n",
       "      <td>2.366517</td>\n",
       "      <td>19.494944</td>\n",
       "      <td>99.741573</td>\n",
       "      <td>2.295112</td>\n",
       "      <td>2.029270</td>\n",
       "      <td>0.361854</td>\n",
       "      <td>1.590899</td>\n",
       "      <td>5.058090</td>\n",
       "      <td>0.957449</td>\n",
       "      <td>2.611685</td>\n",
       "      <td>746.893258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.775035</td>\n",
       "      <td>0.811827</td>\n",
       "      <td>1.117146</td>\n",
       "      <td>0.274344</td>\n",
       "      <td>3.339564</td>\n",
       "      <td>14.282484</td>\n",
       "      <td>0.625851</td>\n",
       "      <td>0.998859</td>\n",
       "      <td>0.124453</td>\n",
       "      <td>0.572359</td>\n",
       "      <td>2.318286</td>\n",
       "      <td>0.228572</td>\n",
       "      <td>0.709990</td>\n",
       "      <td>314.907474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.030000</td>\n",
       "      <td>0.740000</td>\n",
       "      <td>1.360000</td>\n",
       "      <td>10.600000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.340000</td>\n",
       "      <td>0.130000</td>\n",
       "      <td>0.410000</td>\n",
       "      <td>1.280000</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>1.270000</td>\n",
       "      <td>278.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.362500</td>\n",
       "      <td>1.602500</td>\n",
       "      <td>2.210000</td>\n",
       "      <td>17.200000</td>\n",
       "      <td>88.000000</td>\n",
       "      <td>1.742500</td>\n",
       "      <td>1.205000</td>\n",
       "      <td>0.270000</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>3.220000</td>\n",
       "      <td>0.782500</td>\n",
       "      <td>1.937500</td>\n",
       "      <td>500.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>13.050000</td>\n",
       "      <td>1.865000</td>\n",
       "      <td>2.360000</td>\n",
       "      <td>19.500000</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>2.355000</td>\n",
       "      <td>2.135000</td>\n",
       "      <td>0.340000</td>\n",
       "      <td>1.555000</td>\n",
       "      <td>4.690000</td>\n",
       "      <td>0.965000</td>\n",
       "      <td>2.780000</td>\n",
       "      <td>673.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>13.677500</td>\n",
       "      <td>3.082500</td>\n",
       "      <td>2.557500</td>\n",
       "      <td>21.500000</td>\n",
       "      <td>107.000000</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>2.875000</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>1.950000</td>\n",
       "      <td>6.200000</td>\n",
       "      <td>1.120000</td>\n",
       "      <td>3.170000</td>\n",
       "      <td>985.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>14.830000</td>\n",
       "      <td>5.800000</td>\n",
       "      <td>3.230000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>162.000000</td>\n",
       "      <td>3.880000</td>\n",
       "      <td>5.080000</td>\n",
       "      <td>0.660000</td>\n",
       "      <td>3.580000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>1.710000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1680.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Class     Alcohol  Malic acid         Ash  Alcalinity of ash  \\\n",
       "count  178.000000  178.000000  178.000000  178.000000         178.000000   \n",
       "mean     0.938202   13.000618    2.336348    2.366517          19.494944   \n",
       "std      0.775035    0.811827    1.117146    0.274344           3.339564   \n",
       "min      0.000000   11.030000    0.740000    1.360000          10.600000   \n",
       "25%      0.000000   12.362500    1.602500    2.210000          17.200000   \n",
       "50%      1.000000   13.050000    1.865000    2.360000          19.500000   \n",
       "75%      2.000000   13.677500    3.082500    2.557500          21.500000   \n",
       "max      2.000000   14.830000    5.800000    3.230000          30.000000   \n",
       "\n",
       "        Magnesium  Total phenols  Flavanoids  Nonflavanoid phenols  \\\n",
       "count  178.000000     178.000000  178.000000            178.000000   \n",
       "mean    99.741573       2.295112    2.029270              0.361854   \n",
       "std     14.282484       0.625851    0.998859              0.124453   \n",
       "min     70.000000       0.980000    0.340000              0.130000   \n",
       "25%     88.000000       1.742500    1.205000              0.270000   \n",
       "50%     98.000000       2.355000    2.135000              0.340000   \n",
       "75%    107.000000       2.800000    2.875000              0.437500   \n",
       "max    162.000000       3.880000    5.080000              0.660000   \n",
       "\n",
       "       Proanthocyanins  Color intensity         Hue  \\\n",
       "count       178.000000       178.000000  178.000000   \n",
       "mean          1.590899         5.058090    0.957449   \n",
       "std           0.572359         2.318286    0.228572   \n",
       "min           0.410000         1.280000    0.480000   \n",
       "25%           1.250000         3.220000    0.782500   \n",
       "50%           1.555000         4.690000    0.965000   \n",
       "75%           1.950000         6.200000    1.120000   \n",
       "max           3.580000        13.000000    1.710000   \n",
       "\n",
       "       OD280/OD315 of diluted wines      Proline  \n",
       "count                    178.000000   178.000000  \n",
       "mean                       2.611685   746.893258  \n",
       "std                        0.709990   314.907474  \n",
       "min                        1.270000   278.000000  \n",
       "25%                        1.937500   500.500000  \n",
       "50%                        2.780000   673.500000  \n",
       "75%                        3.170000   985.000000  \n",
       "max                        4.000000  1680.000000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA WRANGLING\r\n",
    "### Check for Nulls and Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Class                           0\n",
       "Alcohol                         0\n",
       "Malic acid                      0\n",
       "Ash                             0\n",
       "Alcalinity of ash               0\n",
       "Magnesium                       0\n",
       "Total phenols                   0\n",
       "Flavanoids                      0\n",
       "Nonflavanoid phenols            0\n",
       "Proanthocyanins                 0\n",
       "Color intensity                 0\n",
       "Hue                             0\n",
       "OD280/OD315 of diluted wines    0\n",
       "Proline                         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MACHINE LEARNING\r\n",
    "### ML PREP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode target labels with value between 0 and n_classes-1.\r\n",
    "# Import Metrics for use with evaluation\r\n",
    "\r\n",
    "from sklearn.preprocessing import LabelEncoder\r\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_curve, roc_auc_score, confusion_matrix\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>Alcohol</th>\n",
       "      <th>Malic acid</th>\n",
       "      <th>Ash</th>\n",
       "      <th>Alcalinity of ash</th>\n",
       "      <th>Magnesium</th>\n",
       "      <th>Total phenols</th>\n",
       "      <th>Flavanoids</th>\n",
       "      <th>Nonflavanoid phenols</th>\n",
       "      <th>Proanthocyanins</th>\n",
       "      <th>Color intensity</th>\n",
       "      <th>Hue</th>\n",
       "      <th>OD280/OD315 of diluted wines</th>\n",
       "      <th>Proline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>14.10</td>\n",
       "      <td>2.16</td>\n",
       "      <td>2.30</td>\n",
       "      <td>18.0</td>\n",
       "      <td>105</td>\n",
       "      <td>2.95</td>\n",
       "      <td>3.32</td>\n",
       "      <td>0.22</td>\n",
       "      <td>2.38</td>\n",
       "      <td>5.75</td>\n",
       "      <td>1.25</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>2</td>\n",
       "      <td>13.71</td>\n",
       "      <td>5.65</td>\n",
       "      <td>2.45</td>\n",
       "      <td>20.5</td>\n",
       "      <td>95</td>\n",
       "      <td>1.68</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.52</td>\n",
       "      <td>1.06</td>\n",
       "      <td>7.70</td>\n",
       "      <td>0.64</td>\n",
       "      <td>1.74</td>\n",
       "      <td>740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>1</td>\n",
       "      <td>12.64</td>\n",
       "      <td>1.36</td>\n",
       "      <td>2.02</td>\n",
       "      <td>16.8</td>\n",
       "      <td>100</td>\n",
       "      <td>2.02</td>\n",
       "      <td>1.41</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.62</td>\n",
       "      <td>5.75</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1.59</td>\n",
       "      <td>450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>2</td>\n",
       "      <td>13.11</td>\n",
       "      <td>1.90</td>\n",
       "      <td>2.75</td>\n",
       "      <td>25.5</td>\n",
       "      <td>116</td>\n",
       "      <td>2.20</td>\n",
       "      <td>1.28</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.56</td>\n",
       "      <td>7.10</td>\n",
       "      <td>0.61</td>\n",
       "      <td>1.33</td>\n",
       "      <td>425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>2</td>\n",
       "      <td>13.62</td>\n",
       "      <td>4.95</td>\n",
       "      <td>2.35</td>\n",
       "      <td>20.0</td>\n",
       "      <td>92</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.47</td>\n",
       "      <td>1.02</td>\n",
       "      <td>4.40</td>\n",
       "      <td>0.91</td>\n",
       "      <td>2.05</td>\n",
       "      <td>550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>2</td>\n",
       "      <td>13.32</td>\n",
       "      <td>3.24</td>\n",
       "      <td>2.38</td>\n",
       "      <td>21.5</td>\n",
       "      <td>92</td>\n",
       "      <td>1.93</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.45</td>\n",
       "      <td>1.25</td>\n",
       "      <td>8.42</td>\n",
       "      <td>0.55</td>\n",
       "      <td>1.62</td>\n",
       "      <td>650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0</td>\n",
       "      <td>13.30</td>\n",
       "      <td>1.72</td>\n",
       "      <td>2.14</td>\n",
       "      <td>17.0</td>\n",
       "      <td>94</td>\n",
       "      <td>2.40</td>\n",
       "      <td>2.19</td>\n",
       "      <td>0.27</td>\n",
       "      <td>1.35</td>\n",
       "      <td>3.95</td>\n",
       "      <td>1.02</td>\n",
       "      <td>2.77</td>\n",
       "      <td>1285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>2</td>\n",
       "      <td>13.84</td>\n",
       "      <td>4.12</td>\n",
       "      <td>2.38</td>\n",
       "      <td>19.5</td>\n",
       "      <td>89</td>\n",
       "      <td>1.80</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.48</td>\n",
       "      <td>1.56</td>\n",
       "      <td>9.01</td>\n",
       "      <td>0.57</td>\n",
       "      <td>1.64</td>\n",
       "      <td>480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>2</td>\n",
       "      <td>13.40</td>\n",
       "      <td>3.91</td>\n",
       "      <td>2.48</td>\n",
       "      <td>23.0</td>\n",
       "      <td>102</td>\n",
       "      <td>1.80</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.41</td>\n",
       "      <td>7.30</td>\n",
       "      <td>0.70</td>\n",
       "      <td>1.56</td>\n",
       "      <td>750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>1</td>\n",
       "      <td>12.29</td>\n",
       "      <td>1.41</td>\n",
       "      <td>1.98</td>\n",
       "      <td>16.0</td>\n",
       "      <td>85</td>\n",
       "      <td>2.55</td>\n",
       "      <td>2.50</td>\n",
       "      <td>0.29</td>\n",
       "      <td>1.77</td>\n",
       "      <td>2.90</td>\n",
       "      <td>1.23</td>\n",
       "      <td>2.74</td>\n",
       "      <td>428</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Class  Alcohol  Malic acid   Ash  Alcalinity of ash  Magnesium  \\\n",
       "10       0    14.10        2.16  2.30               18.0        105   \n",
       "173      2    13.71        5.65  2.45               20.5         95   \n",
       "61       1    12.64        1.36  2.02               16.8        100   \n",
       "152      2    13.11        1.90  2.75               25.5        116   \n",
       "143      2    13.62        4.95  2.35               20.0         92   \n",
       "148      2    13.32        3.24  2.38               21.5         92   \n",
       "27       0    13.30        1.72  2.14               17.0         94   \n",
       "156      2    13.84        4.12  2.38               19.5         89   \n",
       "174      2    13.40        3.91  2.48               23.0        102   \n",
       "97       1    12.29        1.41  1.98               16.0         85   \n",
       "\n",
       "     Total phenols  Flavanoids  Nonflavanoid phenols  Proanthocyanins  \\\n",
       "10            2.95        3.32                  0.22             2.38   \n",
       "173           1.68        0.61                  0.52             1.06   \n",
       "61            2.02        1.41                  0.53             0.62   \n",
       "152           2.20        1.28                  0.26             1.56   \n",
       "143           2.00        0.80                  0.47             1.02   \n",
       "148           1.93        0.76                  0.45             1.25   \n",
       "27            2.40        2.19                  0.27             1.35   \n",
       "156           1.80        0.83                  0.48             1.56   \n",
       "174           1.80        0.75                  0.43             1.41   \n",
       "97            2.55        2.50                  0.29             1.77   \n",
       "\n",
       "     Color intensity   Hue  OD280/OD315 of diluted wines  Proline  \n",
       "10              5.75  1.25                          3.17     1510  \n",
       "173             7.70  0.64                          1.74      740  \n",
       "61              5.75  0.98                          1.59      450  \n",
       "152             7.10  0.61                          1.33      425  \n",
       "143             4.40  0.91                          2.05      550  \n",
       "148             8.42  0.55                          1.62      650  \n",
       "27              3.95  1.02                          2.77     1285  \n",
       "156             9.01  0.57                          1.64      480  \n",
       "174             7.30  0.70                          1.56      750  \n",
       "97              2.90  1.23                          2.74      428  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = LabelEncoder()\r\n",
    "df['Class'] = le.fit_transform(df['Class'])\r\n",
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2], dtype=int64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Class'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SEPARATE FEATURES AND TARGET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Alcohol</th>\n",
       "      <th>Malic acid</th>\n",
       "      <th>Ash</th>\n",
       "      <th>Alcalinity of ash</th>\n",
       "      <th>Magnesium</th>\n",
       "      <th>Total phenols</th>\n",
       "      <th>Flavanoids</th>\n",
       "      <th>Nonflavanoid phenols</th>\n",
       "      <th>Proanthocyanins</th>\n",
       "      <th>Color intensity</th>\n",
       "      <th>Hue</th>\n",
       "      <th>OD280/OD315 of diluted wines</th>\n",
       "      <th>Proline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Alcohol  Malic acid   Ash  Alcalinity of ash  Magnesium  Total phenols  \\\n",
       "0    14.23        1.71  2.43               15.6        127           2.80   \n",
       "1    13.20        1.78  2.14               11.2        100           2.65   \n",
       "2    13.16        2.36  2.67               18.6        101           2.80   \n",
       "3    14.37        1.95  2.50               16.8        113           3.85   \n",
       "4    13.24        2.59  2.87               21.0        118           2.80   \n",
       "\n",
       "   Flavanoids  Nonflavanoid phenols  Proanthocyanins  Color intensity   Hue  \\\n",
       "0        3.06                  0.28             2.29             5.64  1.04   \n",
       "1        2.76                  0.26             1.28             4.38  1.05   \n",
       "2        3.24                  0.30             2.81             5.68  1.03   \n",
       "3        3.49                  0.24             2.18             7.80  0.86   \n",
       "4        2.69                  0.39             1.82             4.32  1.04   \n",
       "\n",
       "   OD280/OD315 of diluted wines  Proline  \n",
       "0                          3.92     1065  \n",
       "1                          3.40     1050  \n",
       "2                          3.17     1185  \n",
       "3                          3.45     1480  \n",
       "4                          2.93      735  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set the feature variables\r\n",
    "\r\n",
    "df_features = df.drop('Class', axis=1)\r\n",
    "df_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Class\n",
       "0      0\n",
       "1      0\n",
       "2      0\n",
       "3      0\n",
       "4      0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set the target variable\r\n",
    "\r\n",
    "df_target = df[['Class']]\r\n",
    "df_target.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset in train and test with a ratio of 70-30\r\n",
    "\r\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, x_test, Y_train, y_test = train_test_split(df_features, \r\n",
    "                                                    df_target,\r\n",
    "                                                    test_size=0.3,\r\n",
    "                                                     random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((124, 13), (54, 13))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, x_test.shape,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((124, 1), (54, 1))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert data to Tensors for Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([124, 13]) torch.Size([54, 13])\n"
     ]
    }
   ],
   "source": [
    "Xtrain = torch.from_numpy(X_train.values).float()\r\n",
    "Xtest = torch.from_numpy(x_test.values).float()\r\n",
    "print(Xtrain.shape, Xtest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32 torch.float32\n"
     ]
    }
   ],
   "source": [
    "print(Xtrain.dtype, Xtest.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have successfully converted our  X_data into torch tensors of float32 datatype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([124]) torch.Size([54])\n",
      "torch.int64 torch.int64\n"
     ]
    }
   ],
   "source": [
    "# Reshape tensor to 1D\r\n",
    "\r\n",
    "Ytrain = torch.from_numpy(Y_train.values).view(1,-1)[0]\r\n",
    "Ytest = torch.from_numpy(y_test.values).view(1, -1)[0]\r\n",
    "print(Ytrain.shape, Ytest.shape)\r\n",
    "print(Ytrain.dtype, Ytest.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the **view()** to reshape the tensor.<br>\r\n",
    "The loss function doesn't support multi-target and therefore, we should use a 1D Tensor of 1 row containing the labels.<br>\r\n",
    "We have successfully converted our y_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.int64 torch.int64\n"
     ]
    }
   ],
   "source": [
    "print(Ytrain.dtype, Ytest.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch\r\n",
    "### We create a classifier and define our neural network for our model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 13\r\n",
    "output_size = 3\r\n",
    "hidden_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = dict(\r\n",
    "                dataset = \"wine dataset\",\r\n",
    "                architecture = 'Linear', \r\n",
    "                learning_rate = 0.01,\r\n",
    "                loss = nn.NLLLoss(),\r\n",
    "                optimizer = \"adam\",\r\n",
    ")\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset wine dataset\n",
      "architecture Linear\n",
      "learning_rate 0.01\n",
      "loss NLLLoss()\n",
      "optimizer adam\n"
     ]
    }
   ],
   "source": [
    "for k,v in config.items():\r\n",
    "    print(k, v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the neural network\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "class Net(nn.Module):\r\n",
    "    \r\n",
    "    def __init__(self):\r\n",
    "        super(Net, self).__init__()\r\n",
    "        self.fc1 = nn.Linear(config.get(\"input_size\"), config.get(\"hidden_size\"))\r\n",
    "        self.fc2 = nn.Linear(config.get(\"input_size\"), config.get(\"hidden_size\"))\r\n",
    "        self.fc3 = nn.Linear(config.get(\"input_size\"), config.get(\"output_size\"))\r\n",
    "\r\n",
    "    def forward(self, X):\r\n",
    "        X = torch.sigmoid((self.fc1(X)))\r\n",
    "        X = torch.sigmoid(self.fc2(X))\r\n",
    "        X = self.fc3(X)\r\n",
    "\r\n",
    "        return F.log_softmax(X, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\r\n",
    "    \r\n",
    "    def __init__(self):\r\n",
    "        super(Net, self).__init__()\r\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\r\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size)\r\n",
    "        self.fc3 = nn.Linear(hidden_size, output_size)\r\n",
    "\r\n",
    "        self.dropout = nn.Dropout(0.25)\r\n",
    "\r\n",
    "\r\n",
    "    def forward(self, X):\r\n",
    "        X = torch.sigmoid((self.fc1(X)))\r\n",
    "        X = self.dropout(X)\r\n",
    "        X = torch.sigmoid(self.fc2(X))\r\n",
    "        X = self.dropout(X)\r\n",
    "        X = self.fc3(X)\r\n",
    "\r\n",
    "        return F.log_softmax(X, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (fc1): Linear(in_features=13, out_features=100, bias=True)\n",
       "  (fc2): Linear(in_features=100, out_features=100, bias=True)\n",
       "  (fc3): Linear(in_features=100, out_features=3, bias=True)\n",
       "  (dropout): Dropout(p=0.25, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# instantiate model\r\n",
    "model = Net()\r\n",
    "# move model to gpu\r\n",
    "#model.to(device)\r\n",
    "# preview our model\r\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Optimizer and Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#optimizer = optim.Adam(model.parameters(), lr=config.get(\"learning_rate\"))\r\n",
    "loss_fn = config.get(\"loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the optimizer\r\n",
    "\r\n",
    "if config.get(\"optimizer\")=='sgd':\r\n",
    "    optimizer = optim.SGD(model.parameters(),lr=config.get(\"learning_rate\"), momentum=0.9)\r\n",
    "elif config.get(\"optimizer\")=='adam':\r\n",
    "    optimizer = optim.Adam(model.parameters(),lr=config.get(\"learning_rate\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Loss\r\n",
    "\r\n",
    "if config.get(\"loss\") == \"NLLLoss\":\r\n",
    "    loss_fn = nn.NLLLoss()\r\n",
    "elif config.get(\"loss\") == \"CrossEntropyLoss\":\r\n",
    "    loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAIN AND LOG THE MODEL\r\n",
    "### Train the Model for 1000 Epochs\r\n",
    "### Log the model Parameters\r\n",
    "### Export Model, Import and Set to Eval\r\n",
    "### Log Metrics on Model.Eval\r\n",
    "### Convert and Export to ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.33<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">fanciful-spaceship-38</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/markgich/demo_wandb_test\" target=\"_blank\">https://wandb.ai/markgich/demo_wandb_test</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/markgich/demo_wandb_test/runs/157t9rsp\" target=\"_blank\">https://wandb.ai/markgich/demo_wandb_test/runs/157t9rsp</a><br/>\n",
       "                Run data is saved locally in <code>c:\\Users\\markg\\Documents\\PROGRAMMING\\PYTHON_PROJECTS\\TORCH\\DEMO_WINE_WANDB\\wandb\\run-20210709_233506-157t9rsp</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Calling run.save without any arguments is deprecated.Changes to attributes are automatically persisted.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph(%input : Float(124, 13, strides=[1, 124], requires_grad=0, device=cpu),\n",
      "      %fc1.weight : Float(100, 13, strides=[13, 1], requires_grad=1, device=cpu),\n",
      "      %fc1.bias : Float(100, strides=[1], requires_grad=1, device=cpu),\n",
      "      %fc2.weight : Float(100, 100, strides=[100, 1], requires_grad=1, device=cpu),\n",
      "      %fc2.bias : Float(100, strides=[1], requires_grad=1, device=cpu),\n",
      "      %fc3.weight : Float(3, 100, strides=[100, 1], requires_grad=1, device=cpu),\n",
      "      %fc3.bias : Float(3, strides=[1], requires_grad=1, device=cpu)):\n",
      "  %7 : Float(124, 100, strides=[100, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%input, %fc1.weight, %fc1.bias) # c:\\Users\\markg\\venv\\torch-venv\\lib\\site-packages\\torch\\nn\\functional.py:1753:0\n",
      "  %8 : Float(124, 100, strides=[100, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%7) # c:\\Users\\markg\\venv\\torch-venv\\lib\\site-packages\\torch\\nn\\functional.py:1076:0\n",
      "  %9 : Float(124, 100, strides=[100, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%8, %fc2.weight, %fc2.bias) # c:\\Users\\markg\\venv\\torch-venv\\lib\\site-packages\\torch\\nn\\functional.py:1753:0\n",
      "  %10 : Float(124, 100, strides=[100, 1], requires_grad=1, device=cpu) = onnx::Sigmoid(%9) # c:\\Users\\markg\\venv\\torch-venv\\lib\\site-packages\\torch\\nn\\functional.py:1076:0\n",
      "  %11 : Float(124, 3, strides=[3, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%10, %fc3.weight, %fc3.bias) # c:\\Users\\markg\\venv\\torch-venv\\lib\\site-packages\\torch\\nn\\functional.py:1753:0\n",
      "  %output : Float(124, 3, strides=[3, 1], requires_grad=1, device=cpu) = onnx::LogSoftmax[axis=1](%11) # c:\\Users\\markg\\venv\\torch-venv\\lib\\site-packages\\torch\\nn\\functional.py:1672:0\n",
      "  return (%output)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 38020<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5990dec4d6e44370a6acdc64a9ccd2f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>c:\\Users\\markg\\Documents\\PROGRAMMING\\PYTHON_PROJECTS\\TORCH\\DEMO_WINE_WANDB\\wandb\\run-20210709_233506-157t9rsp\\logs\\debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>c:\\Users\\markg\\Documents\\PROGRAMMING\\PYTHON_PROJECTS\\TORCH\\DEMO_WINE_WANDB\\wandb\\run-20210709_233506-157t9rsp\\logs\\debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>Epoch</td><td>999</td></tr><tr><td>Loss</td><td>0.4862</td></tr><tr><td>Accuracy</td><td>0.79032</td></tr><tr><td>_runtime</td><td>12</td></tr><tr><td>_timestamp</td><td>1625862918</td></tr><tr><td>_step</td><td>1001</td></tr><tr><td>accuracy_score</td><td>0.92593</td></tr><tr><td>precision_score</td><td>0.92737</td></tr><tr><td>recall_score</td><td>0.92593</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>Epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>Loss</td><td>█▅▆▅▄▄▃▃▃▃▂▂▂▂▂▂▂▂▃▁▂▂▂▂▃▂▂▂▁▂▂▂▃▃▃▂▁▁▂▃</td></tr><tr><td>Accuracy</td><td>▁▃▃▃▄▄▆▆▆▆▆▇█▇█▇▇▇▇█▇▇▇▇▇▇▇▇█▇▇▇▆▇▆▇██▇▆</td></tr><tr><td>_runtime</td><td>▁▁▁▁▁▁▁▃▃▃▃▃▃▃▃▃▅▅▅▅▅▅▅▅▅▅▆▆▆▆▆▆▆▆▆█████</td></tr><tr><td>_timestamp</td><td>▁▁▁▁▁▁▁▃▃▃▃▃▃▃▃▃▅▅▅▅▅▅▅▅▅▅▆▆▆▆▆▆▆▆▆█████</td></tr><tr><td>_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>accuracy_score</td><td>▁</td></tr><tr><td>precision_score</td><td>▁</td></tr><tr><td>recall_score</td><td>▁</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 2 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">fanciful-spaceship-38</strong>: <a href=\"https://wandb.ai/markgich/demo_wandb_test/runs/157t9rsp\" target=\"_blank\">https://wandb.ai/markgich/demo_wandb_test/runs/157t9rsp</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TRAIN THE MODEL\r\n",
    "\r\n",
    "\r\n",
    "epochs = 1000\r\n",
    "with wandb.init(project=\"demo_wandb_test\", config = config):\r\n",
    "    wandb.watch(model, criterion=None, log=\"all\", log_freq=10)\r\n",
    "    \r\n",
    "    for epoch in range(epochs):\r\n",
    "        # zero the gradients\r\n",
    "        optimizer.zero_grad()\r\n",
    "        # train the model\r\n",
    "        Ypred = model(Xtrain)\r\n",
    "        # compute the accuract\r\n",
    "        acc = torchmetrics.functional.accuracy(Ypred, Ytrain)\r\n",
    "        # compute the loss\r\n",
    "        loss = loss_fn(Ypred, Ytrain)\r\n",
    "        # update the model weights\r\n",
    "        loss.backward()\r\n",
    "        # optimize the learning parameters and step forward\r\n",
    "        optimizer.step()\r\n",
    "        # log the metrics\r\n",
    "        wandb.log({'Epoch': epoch, \"Loss\": loss.item(), \"Accuracy\": acc})\r\n",
    "\r\n",
    "\r\n",
    "    # SAVE MODEL STATE DICT TO DISK\r\n",
    "\r\n",
    "    wandb.save(torch.save(model.state_dict(), \"./models/home_state_dict.pt\"))\r\n",
    "\r\n",
    "    # LOAD MODEL FROM DISK and EVALUATE\r\n",
    "\r\n",
    "    new_model =  Net()\r\n",
    "    new_model.load_state_dict(torch.load(\"./models/home_state_dict.pt\"))\r\n",
    "    new_model.eval()\r\n",
    "\r\n",
    "    # SET THE PREDICTIONS\r\n",
    "\r\n",
    "    predict = new_model(Xtest)\r\n",
    "    _, predict_y = torch.max(predict, 1)\r\n",
    "\r\n",
    "\r\n",
    "    # VISUALIZE CONFUSION MATRIX\r\n",
    "    wandb.sklearn.plot_confusion_matrix(Ytest, predict_y, labels = [0,1,2])\r\n",
    "\r\n",
    "    # Print Metrics\r\n",
    "\r\n",
    "    wandb.log({\"accuracy_score\" : accuracy_score(Ytest, predict_y),\r\n",
    "    \"precision_score\" : precision_score(Ytest, predict_y, average='weighted'),\r\n",
    "    \"recall_score\": recall_score(Ytest, predict_y, average=\"weighted\"),\r\n",
    "    \r\n",
    "    })\r\n",
    "    \r\n",
    "    torch.onnx.export(model = model,args =  (Xtrain), f = \"./models/home_state_test.onnx\", input_names=['input'], output_names = ['output'],\r\n",
    "    verbose=True, do_constant_folding=True, opset_version=11)\r\n",
    "wandb.finish()\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OPTIMIZE NETWORK WITH SWEEPS\r\n",
    "### WANDB SWEEPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace agent with own agent line generated from project\r\n",
    "!wandb agent markgich/demo_wandb_test/izsvluxh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep_config = {\r\n",
    "    'method': 'grid', #grid, random\r\n",
    "    'metric': {\r\n",
    "      'name': 'loss',\r\n",
    "      'goal': 'minimize'   \r\n",
    "    },\r\n",
    "    'parameters': {\r\n",
    "        'epochs': {\r\n",
    "            'values': [100, 500, 1000]\r\n",
    "        },\r\n",
    "        \r\n",
    "        'learning_rate': {\r\n",
    "            'values': [1e-2, 1e-3, 1e-4, 3e-4, 3e-5, 1e-5]\r\n",
    "        },\r\n",
    "        'fc_layer_size':{\r\n",
    "            'values':[128,256,512]\r\n",
    "        },\r\n",
    "        'optimizer': {\r\n",
    "            'values': ['adam', 'sgd']\r\n",
    "        },\r\n",
    "        'loss':{\r\n",
    "            'values':[\"NLLLoss\", \"CategoricalCrossEntropy\"]\r\n",
    "        }\r\n",
    "    }\r\n",
    "}\r\n",
    "sweep_id = wandb.sweep(sweep_config)\r\n",
    "#wandb.agent(sweep_id=sweep_id, project=\"demo_wandb_test\", )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ADD HYPERPARAMETER TUNING SWEEPS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEMO OF IT\r\n",
    "def train():\r\n",
    "    with wandb.init() as run:\r\n",
    "        config = wandb.config\r\n",
    "        model = Model(config)\r\n",
    "        for epoch in range(config[\"epochs\"]):\r\n",
    "            loss = model.fit()  # your model training code here\r\n",
    "            wandb.log({\"loss\": loss, \"epoch\": epoch})\r\n",
    "\r\n",
    "count = 5 # number of runs to execute\r\n",
    "wandb.agent(sweep_id, function=train, count=count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\r\n",
    "def train():\r\n",
    "    # TRAIN THE MODEL\r\n",
    "    epochs = 1000\r\n",
    "    with wandb.init(project=\"demo_wandb_test\", config = config):\r\n",
    "        #wandb.watch(model, criterion=None, log=\"gradients\", log_freq=10)\r\n",
    "        \r\n",
    "        for epoch in range(epochs):\r\n",
    "            # zero the gradients\r\n",
    "            optimizer.zero_grad()\r\n",
    "            # train the model\r\n",
    "            Ypred = model(Xtrain)\r\n",
    "            # compute the accuract\r\n",
    "            acc = torchmetrics.functional.accuracy(Ypred, Ytrain)\r\n",
    "            # compute the loss\r\n",
    "            loss = loss_fn(Ypred, Ytrain)\r\n",
    "            # update the model weights\r\n",
    "            loss.backward()\r\n",
    "            # optimize the learning parameters and step forward\r\n",
    "            optimizer.step()\r\n",
    "            # log the metrics\r\n",
    "            wandb.log({'Epoch': epoch, \"Loss\": loss.item(), \"Accuracy\": acc})\r\n",
    "\r\n",
    "\r\n",
    "        # SAVE MODEL STATE DICT TO DISK\r\n",
    "\r\n",
    "        wandb.save(torch.save(model.state_dict(), \"./models/home_state_dict.pt\"))\r\n",
    "\r\n",
    "        # LOAD MODEL FROM DISK and EVALUATE\r\n",
    "\r\n",
    "        new_model =  Net()\r\n",
    "        new_model.load_state_dict(torch.load(\"./models/home_state_dict.pt\"))\r\n",
    "        new_model.eval()\r\n",
    "\r\n",
    "        # SET THE PREDICTIONS\r\n",
    "\r\n",
    "        predict = new_model(Xtest)\r\n",
    "        _, predict_y = torch.max(predict, 1)\r\n",
    "\r\n",
    "\r\n",
    "        # VISUALIZE CONFUSION MATRIX\r\n",
    "        wandb.sklearn.plot_confusion_matrix(Ytest, predict_y, labels = [0,1,2])\r\n",
    "\r\n",
    "        # Print Metrics\r\n",
    "\r\n",
    "        wandb.log({\"accuracy_score\" : accuracy_score(Ytest, predict_y),\r\n",
    "        \"precision_score\" : precision_score(Ytest, predict_y, average='weighted'),\r\n",
    "        \"recall_score\": recall_score(Ytest, predict_y, average=\"weighted\"),\r\n",
    "        \r\n",
    "        })\r\n",
    "        \r\n",
    "        torch.onnx.export(model = model,args =  (Xtrain), f = \"./models/home_state_test.onnx\", input_names=['input'], output_names = ['output'],\r\n",
    "        verbose=True, do_constant_folding=True, opset_version=11)\r\n",
    "    wandb.finish()\r\n",
    "\r\n",
    "count = 5 # number of runs to execute\r\n",
    "wandb.agent(sweep_id = sweep_id, project=\"demo_wandb_test\", function=train(), count=count)\r\n",
    "#wandb.agent(sweep_id=sweep_id, project=\"demo_wandb_test\", )"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "778de6fd147bda85163a324ce7339acfc1c656b45f8b8593316159881a238432"
  },
  "kernelspec": {
   "display_name": "Python 3.8.6 64-bit ('torch-venv': venv)",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": ""
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}