{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\r\n",
    "from torch import nn\r\n",
    "import torch.nn.functional as F\r\n",
    "from torch.utils.data import DataLoader\r\n",
    "from torchvision import datasets\r\n",
    "from torchvision.transforms import ToTensor, Lambda\r\n",
    "from torch import optim\r\n",
    "import torchmetrics\r\n",
    "\r\n",
    "import numpy as np\r\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\r\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\r\n",
    "training_data = datasets.FashionMNIST(\r\n",
    "    root=\"data\",\r\n",
    "    train=True,\r\n",
    "    download=True,\r\n",
    "    transform=ToTensor()\r\n",
    ")\r\n",
    "\r\n",
    "test_data = datasets.FashionMNIST(\r\n",
    "    root=\"data\",\r\n",
    "    train=False,\r\n",
    "    download=True,\r\n",
    "    transform=ToTensor()\r\n",
    ")\r\n",
    "\r\n",
    "train_dataloader = DataLoader(training_data, batch_size=64)\r\n",
    "test_dataloader = DataLoader(test_data, batch_size=64)\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VISUALIZE TRAIN IMAGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\r\n",
    "\r\n",
    "def imshow(inp, title=None, ax=None, figsize=(5, 5)):\r\n",
    "  \"\"\"Imshow for Tensor.\"\"\"\r\n",
    "  inp = inp.numpy().transpose((1, 2, 0))\r\n",
    "  mean = np.array([0.485, 0.456, 0.406])\r\n",
    "  std = np.array([0.229, 0.224, 0.225])\r\n",
    "  inp = std * inp + mean\r\n",
    "  inp = np.clip(inp, 0, 1)\r\n",
    "  if ax is None:\r\n",
    "    fig, ax = plt.subplots(1, figsize=figsize)\r\n",
    "  ax.imshow(inp)\r\n",
    "  ax.set_xticks([])\r\n",
    "  ax.set_yticks([])\r\n",
    "  if title is not None:\r\n",
    "    ax.set_title(title)\r\n",
    "\r\n",
    "# Get a batch of training data\r\n",
    "inputs, classes = next(iter(train_dataloader))\r\n",
    "\r\n",
    "# Make a grid from batch\r\n",
    "out = torchvision.utils.make_grid(inputs, nrow=4)\r\n",
    "\r\n",
    "fig, ax = plt.subplots(1, figsize=(10, 10))\r\n",
    "imshow(out,\r\n",
    "        #title=[class_names[x] for x in classes],\r\n",
    "        ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LINEAR NEURAL NET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\r\n",
    "    def __init__(self):\r\n",
    "        super(NeuralNetwork, self).__init__()\r\n",
    "        self.flatten = nn.Flatten()\r\n",
    "        self.linear_relu_stack = nn.Sequential(\r\n",
    "            nn.Linear(28*28, 512),\r\n",
    "            nn.ReLU(),\r\n",
    "            nn.Dropout(p=0.25),\r\n",
    "            nn.Linear(512, 512),\r\n",
    "            nn.ReLU(),\r\n",
    "            nn.Dropout(p=0.25),\r\n",
    "            nn.Linear(512, 10),\r\n",
    "            nn.ReLU()\r\n",
    "        )\r\n",
    "\r\n",
    "    def forward(self, x):\r\n",
    "        x = self.flatten(x)\r\n",
    "        logits = self.linear_relu_stack(x)\r\n",
    "        return logits\r\n",
    "\r\n",
    "model = NeuralNetwork()\r\n",
    "model.to(device)\r\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  CONVOLUTION NEURAL NETWORK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "class ConvNet(nn.Module):\r\n",
    "    def __init__(self, input_shape=(1,28,28)):\r\n",
    "        super(ConvNet, self).__init__()\r\n",
    "\r\n",
    "        # DEFINE THE CONVOLUTION LAYERS\r\n",
    "\r\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3)\r\n",
    "        self.conv2 = nn.Conv2d(32, 64,3)\r\n",
    "        self.conv3 = nn.Conv2d(64, 128, 3)\r\n",
    "\r\n",
    "        # DEFINE THE POOLING LATER\r\n",
    "\r\n",
    "        self.pool = nn.MaxPool2d(2, 2)\r\n",
    "\r\n",
    "        n_size = self._get_conv_output(input_shape)\r\n",
    "\r\n",
    "        # DEFINE THE LINEAR CLASSS\r\n",
    "\r\n",
    "        self.fc1 = nn.Linear(n_size, 512)\r\n",
    "        self.fc2 = nn.Linear(512, 10)\r\n",
    "\r\n",
    "        # DEFINE THE DROPOUT\r\n",
    "        self.dropout = nn.Dropout(p=0.25)\r\n",
    "\r\n",
    "    def _get_conv_output(self, shape):\r\n",
    "        batch_size = 1\r\n",
    "        input = torch.autograd.Variable(torch.rand(batch_size, *shape))\r\n",
    "        output_feat = self._forward_features(input)\r\n",
    "        n_size = output_feat.data.view(batch_size, -1).size(1)\r\n",
    "        return n_size\r\n",
    "\r\n",
    "    def _forward_features(self, X):\r\n",
    "        X = self.pool(F.relu(self.conv1(X)))\r\n",
    "        X = self.pool(F.relu(self.conv2(X)))\r\n",
    "        X = self.pool(F.relu(self.conv3(X)))\r\n",
    "        return X\r\n",
    "\r\n",
    "    def forward(self, X):\r\n",
    "        X = self._forward_features(X)\r\n",
    "        X = X.view(X.size(0), -1)\r\n",
    "        X = self.dropout(X) # DROPOUT\r\n",
    "        X = F.relu(self.fc1(X))\r\n",
    "        X = self.dropout(X) # DROPOUT\r\n",
    "        X = self.fc2(X)\r\n",
    "        return X\r\n",
    "        \r\n",
    "model = ConvNet()\r\n",
    "\r\n",
    "# PUSH MODEL TO DEVICE(CUDA)\r\n",
    "model.to(device)\r\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HYPERPARAMETERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = dict(learning_rate = 1e-3,\r\n",
    "                batch_size = 64,\r\n",
    "                epochs = 10,\r\n",
    "                loss = nn.CrossEntropyLoss(),\r\n",
    "                #loss = nn.NLLLoss(),\r\n",
    "                optimizer = torch.optim.Adagrad(model.parameters(), lr=1e-5)\r\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in config.items():\r\n",
    "    print(f\"{k}: {v}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer):\r\n",
    "    size = len(dataloader.dataset)\r\n",
    "    #acc = 0\r\n",
    "    for batch, (X, y) in enumerate(dataloader):\r\n",
    "        X, y = X.to(device), y.to(device)\r\n",
    "        # Compute prediction and loss\r\n",
    "        pred = model(X)\r\n",
    "        loss = loss_fn(pred, y)\r\n",
    "        acc = torchmetrics.functional.accuracy(pred, y)\r\n",
    "\r\n",
    "        # Backpropagation\r\n",
    "        optimizer.zero_grad()\r\n",
    "        loss.backward()\r\n",
    "        optimizer.step()\r\n",
    "\r\n",
    "        if batch % 100 == 0:\r\n",
    "            loss, current = loss.item(), batch * len(X)\r\n",
    "            print(f\"train loss: {loss:>3f}  [{current:>5d}/{size:>5d}]\")\r\n",
    "            #wandb.log({\"train loss\": loss, \"train accuracy\": acc})\r\n",
    "    print(f\"Train Metrics: \\n Train Accuracy: {(100*acc):>0.1f}%, Train Loss: {loss:>8f} \\n\")\r\n",
    "    wandb.log({\"Train Accuracy\": acc, \"Train Loss\": loss })\r\n",
    "\r\n",
    "\r\n",
    "def test_loop(dataloader, model, loss_fn):\r\n",
    "    size = len(dataloader.dataset)\r\n",
    "    num_batches = len(dataloader)\r\n",
    "    test_loss, correct = 0, 0\r\n",
    "\r\n",
    "    with torch.no_grad():\r\n",
    "        for X, y in dataloader:\r\n",
    "            X, y = X.to(device), y.to(device)\r\n",
    "            pred = model(X)\r\n",
    "            test_loss += loss_fn(pred, y).item()\r\n",
    "            acc = torchmetrics.functional.accuracy(pred, y)\r\n",
    "            #correct += (pred.argmax(1) == y).type(torch.float).sum().item()\r\n",
    "    wandb.log({\"Test Accuracy\":acc, \"Test Loss\": test_loss})\r\n",
    "\r\n",
    "    test_loss /= num_batches\r\n",
    "    correct /= size\r\n",
    "    #print(f\"Test Metrics: \\n Test Accuracy: {(100*correct):>0.1f}%, Test Loss: {test_loss:>8f} \\n\")\r\n",
    "    print(f\"Test Metrics: \\n Test Accuracy: {(100*acc):>0.1f}%, Test Loss: {test_loss:>8f} \\n\")\r\n",
    "    #wandb.log({\"Test Accuracy\":acc, \"Test Loss\": test_loss})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define loss and optimizer\r\n",
    "\r\n",
    "#loss_fn = nn.NLLLoss()\r\n",
    "#loss_fn = config.get(\"loss\")\r\n",
    "loss_fn = nn.CrossEntropyLoss()\r\n",
    "\r\n",
    "#optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\r\n",
    "#optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\r\n",
    "optimizer = torch.optim.Adagrad(model.parameters(), lr=config.get(\"learning_rate\"))\r\n",
    "#optimizer = config.get(\"optimizer\")\r\n",
    "\r\n",
    "print(loss_fn, optimizer)\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\r\n",
    "def train():\r\n",
    "    # train with wandb sweeps\r\n",
    "    with wandb.init(project=\"demo_wandb_fashionmnsit_test\", config=config):\r\n",
    "        \r\n",
    "        wandb.watch(model, criterion=loss_fn, log=\"all\", log_freq=10)\r\n",
    "        \r\n",
    "        epochs = 10\r\n",
    "        for t in range(epochs):\r\n",
    "\r\n",
    "            print(f\"Epoch {t+1}\\n-------------------------------\")\r\n",
    "            train_loop(train_dataloader, model, loss_fn, optimizer)\r\n",
    "            test_loop(test_dataloader, model, loss_fn)\r\n",
    "        wandb.save(torch.save(model.state_dict(), f=f\"./models/fashion_mnist_{t}.pt\"))\r\n",
    "    print(\"Done!\")\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HYPER PARAMETER OPTIMIZATION\r\n",
    "## SWEEPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this line initializes the sweep\r\n",
    "sweep_id = wandb.sweep({'name': 'my-awesome-sweep',\r\n",
    "                        'metric': 'accuracy',\r\n",
    "                        'method': 'grid',\r\n",
    "                        'parameters': {'a': {'values': [1, 2, 3, 4]}}})\r\n",
    "\r\n",
    "# this line actually runs it -- parameters are available to\r\n",
    "# my_train_func via wandb.config\r\n",
    "wandb.agent(sweep_id, function=my_train_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep_config = {\r\n",
    "    'method': 'grid', #grid, random\r\n",
    "    'metric': {\r\n",
    "      'name': 'loss',\r\n",
    "      'goal': 'minimize'   \r\n",
    "    },\r\n",
    "    'metric':{\r\n",
    "        'name': 'accuracy',\r\n",
    "        'goal':'maximize'\r\n",
    "    },\r\n",
    "    'parameters': {\r\n",
    "        'epochs': {\r\n",
    "            'values': [2, 5, 10]\r\n",
    "        },\r\n",
    "        'batch_size': {\r\n",
    "            'values': [ 64, 32, 16, 8]\r\n",
    "        },\r\n",
    "        'dropout': {\r\n",
    "            'values': [0.1, 0.3, 0.5]\r\n",
    "        },\r\n",
    "        'learning_rate': {\r\n",
    "            'values': [1e-2, 1e-3, 1e-4, 3e-4, 3e-5, 1e-5]\r\n",
    "        },\r\n",
    "        'fc_layer_size':{\r\n",
    "            'values':[128,256,512]\r\n",
    "        },\r\n",
    "        'optimizer': {\r\n",
    "            'values': ['adam', 'sgd', 'adagrad']\r\n",
    "        },\r\n",
    "    }\r\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep_id = wandb.sweep(sweep_config, project=\"demo_wandb_fashionmnsit_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.agent(sweep_id, train, count=5)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "778de6fd147bda85163a324ce7339acfc1c656b45f8b8593316159881a238432"
  },
  "kernelspec": {
   "display_name": "Python 3.8.6 64-bit ('torch-venv': venv)",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": ""
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}