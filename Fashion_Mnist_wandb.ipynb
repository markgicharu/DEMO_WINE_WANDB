{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\r\n",
    "from torch import nn\r\n",
    "import torch.nn.functional as F\r\n",
    "from torch.utils.data import DataLoader\r\n",
    "from torchvision import datasets\r\n",
    "from torchvision.transforms import ToTensor, Lambda\r\n",
    "from torch import optim\r\n",
    "\r\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "wandb: Currently logged in as: markgich (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\r\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\r\n",
    "training_data = datasets.FashionMNIST(\r\n",
    "    root=\"data\",\r\n",
    "    train=True,\r\n",
    "    download=True,\r\n",
    "    transform=ToTensor()\r\n",
    ")\r\n",
    "\r\n",
    "test_data = datasets.FashionMNIST(\r\n",
    "    root=\"data\",\r\n",
    "    train=False,\r\n",
    "    download=True,\r\n",
    "    transform=ToTensor()\r\n",
    ")\r\n",
    "\r\n",
    "train_dataloader = DataLoader(training_data, batch_size=64)\r\n",
    "test_dataloader = DataLoader(test_data, batch_size=64)\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LINEAR NEURAL NET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeuralNetwork(\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (linear_relu_stack): Sequential(\n",
       "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.25, inplace=False)\n",
       "    (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (4): ReLU()\n",
       "    (5): Dropout(p=0.25, inplace=False)\n",
       "    (6): Linear(in_features=512, out_features=10, bias=True)\n",
       "    (7): ReLU()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class NeuralNetwork(nn.Module):\r\n",
    "    def __init__(self):\r\n",
    "        super(NeuralNetwork, self).__init__()\r\n",
    "        self.flatten = nn.Flatten()\r\n",
    "        self.linear_relu_stack = nn.Sequential(\r\n",
    "            nn.Linear(28*28, 512),\r\n",
    "            nn.ReLU(),\r\n",
    "            nn.Dropout(p=0.25),\r\n",
    "            nn.Linear(512, 512),\r\n",
    "            nn.ReLU(),\r\n",
    "            nn.Dropout(p=0.25),\r\n",
    "            nn.Linear(512, 10),\r\n",
    "            nn.ReLU()\r\n",
    "        )\r\n",
    "\r\n",
    "    def forward(self, x):\r\n",
    "        x = self.flatten(x)\r\n",
    "        logits = self.linear_relu_stack(x)\r\n",
    "        return logits\r\n",
    "\r\n",
    "model = NeuralNetwork()\r\n",
    "model.to(device)\r\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  CONVOLUTION NEURAL NETWORK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "class ConvNet(nn.Module):\r\n",
    "    def __init__(self, input_shape=(1,28,28)):\r\n",
    "        super(ConvNet, self).__init__()\r\n",
    "\r\n",
    "        # DEFINE THE CONVOLUTION LAYERS\r\n",
    "\r\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3)\r\n",
    "        self.conv2 = nn.Conv2d(32, 64,3)\r\n",
    "        self.conv3 = nn.Conv2d(64, 128, 3)\r\n",
    "\r\n",
    "        # DEFINE THE POOLING LATER\r\n",
    "\r\n",
    "        self.pool = nn.MaxPool2d(2, 2)\r\n",
    "\r\n",
    "        n_size = self._get_conv_output(input_shape)\r\n",
    "\r\n",
    "        # DEFINE THE LINEAR CLASSS\r\n",
    "\r\n",
    "        self.fc1 = nn.Linear(n_size, 512)\r\n",
    "        self.fc2 = nn.Linear(512, 10)\r\n",
    "\r\n",
    "        # DEFINE THE DROPOUT\r\n",
    "        self.dropout = nn.Dropout(p=0.25)\r\n",
    "\r\n",
    "    def _get_conv_output(self, shape):\r\n",
    "        batch_size = 1\r\n",
    "        input = torch.autograd.Variable(torch.rand(batch_size, *shape))\r\n",
    "        output_feat = self._forward_features(input)\r\n",
    "        n_size = output_feat.data.view(batch_size, -1).size(1)\r\n",
    "        return n_size\r\n",
    "\r\n",
    "    def _forward_features(self, X):\r\n",
    "        X = self.pool(F.relu(self.conv1(X)))\r\n",
    "        X = self.pool(F.relu(self.conv2(X)))\r\n",
    "        X = self.pool(F.relu(self.conv3(X)))\r\n",
    "        return X\r\n",
    "\r\n",
    "    def forward(self, X):\r\n",
    "        X = self._forward_features(X)\r\n",
    "        X = X.view(X.size(0), -1)\r\n",
    "        X = self.dropout(X) # DROPOUT\r\n",
    "        X = F.relu(self.fc1(X))\r\n",
    "        X = self.dropout(X) # DROPOUT\r\n",
    "        X = self.fc2(X)\r\n",
    "        return X\r\n",
    "        \r\n",
    "model = ConvNet()\r\n",
    "\r\n",
    "# PUSH MODEL TO DEVICE(CUDA)\r\n",
    "model.to(device)\r\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HYPERPARAMETERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = dict(learning_rate = 1e-3,\r\n",
    "                batch_size = 64,\r\n",
    "                epochs = 10\r\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning_rate: 0.001\n",
      "batch_size: 64\n",
      "epochs: 10\n"
     ]
    }
   ],
   "source": [
    "for k, v in config.items():\r\n",
    "    print(f\"{k}: {v}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer):\r\n",
    "    size = len(dataloader.dataset)\r\n",
    "    for batch, (X, y) in enumerate(dataloader):\r\n",
    "        X, y = X.to(device), y.to(device)\r\n",
    "        # Compute prediction and loss\r\n",
    "        pred = model(X)\r\n",
    "        loss = loss_fn(pred, y)\r\n",
    "\r\n",
    "        # Backpropagation\r\n",
    "        optimizer.zero_grad()\r\n",
    "        loss.backward()\r\n",
    "        optimizer.step()\r\n",
    "\r\n",
    "        if batch % 100 == 0:\r\n",
    "            loss, current = loss.item(), batch * len(X)\r\n",
    "            print(f\"loss: {loss:>3f}  [{current:>5d}/{size:>5d}]\")\r\n",
    "            wandb.log({\"train loss\": loss, \"train accuracy\": current/size})\r\n",
    "\r\n",
    "\r\n",
    "def test_loop(dataloader, model, loss_fn):\r\n",
    "    size = len(dataloader.dataset)\r\n",
    "    num_batches = len(dataloader)\r\n",
    "    test_loss, correct = 0, 0\r\n",
    "\r\n",
    "    with torch.no_grad():\r\n",
    "        for X, y in dataloader:\r\n",
    "            X, y = X.to(device), y.to(device)\r\n",
    "            pred = model(X)\r\n",
    "            test_loss += loss_fn(pred, y).item()\r\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\r\n",
    "\r\n",
    "    test_loss /= num_batches\r\n",
    "    correct /= size\r\n",
    "    print(f\"Test Metrics: \\n Accuracy: {(100*correct):>0.1f}%, Test loss: {test_loss:>8f} \\n\")\r\n",
    "    wandb.log({\"Accuracy\":correct, \"Loss\": test_loss})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define loss and optimizer\r\n",
    "\r\n",
    "#loss_fn = nn.NLLLoss()\r\n",
    "loss_fn = nn.CrossEntropyLoss()\r\n",
    "#optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\r\n",
    "#optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\r\n",
    "optimizer = torch.optim.Adagrad(model.parameters(), lr=config.get(\"learning_rate\"))\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.33<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">dulcet-lion-6</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/markgich/demo_wandb_fashionmnsit_test\" target=\"_blank\">https://wandb.ai/markgich/demo_wandb_fashionmnsit_test</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/markgich/demo_wandb_fashionmnsit_test/runs/32shoccg\" target=\"_blank\">https://wandb.ai/markgich/demo_wandb_fashionmnsit_test/runs/32shoccg</a><br/>\n",
       "                Run data is saved locally in <code>c:\\Users\\markg\\Documents\\PROGRAMMING\\PYTHON_PROJECTS\\TORCH\\DEMO_WINE_WANDB\\wandb\\run-20210710_151157-32shoccg</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.304830  [    0/60000]\n",
      "loss: 1.296517  [ 6400/60000]\n",
      "loss: 0.992931  [12800/60000]\n",
      "loss: 1.227793  [19200/60000]\n",
      "loss: 0.956406  [25600/60000]\n",
      "loss: 0.858566  [32000/60000]\n",
      "loss: 0.889584  [38400/60000]\n",
      "loss: 0.796505  [44800/60000]\n",
      "loss: 0.735941  [51200/60000]\n",
      "loss: 0.839347  [57600/60000]\n",
      "Test Metrics: \n",
      " Accuracy: 77.5%, Test loss: 0.771421 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.745508  [    0/60000]\n",
      "loss: 0.893211  [ 6400/60000]\n",
      "loss: 0.672587  [12800/60000]\n",
      "loss: 0.765295  [19200/60000]\n",
      "loss: 0.729331  [25600/60000]\n",
      "loss: 0.649548  [32000/60000]\n",
      "loss: 0.686472  [38400/60000]\n",
      "loss: 0.809929  [44800/60000]\n",
      "loss: 0.701262  [51200/60000]\n",
      "loss: 0.825642  [57600/60000]\n",
      "Test Metrics: \n",
      " Accuracy: 78.2%, Test loss: 0.723293 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.705242  [    0/60000]\n",
      "loss: 0.780657  [ 6400/60000]\n",
      "loss: 0.594270  [12800/60000]\n",
      "loss: 0.754315  [19200/60000]\n",
      "loss: 0.716219  [25600/60000]\n",
      "loss: 0.624991  [32000/60000]\n",
      "loss: 0.629592  [38400/60000]\n",
      "loss: 0.821568  [44800/60000]\n",
      "loss: 0.654789  [51200/60000]\n",
      "loss: 0.809528  [57600/60000]\n",
      "Test Metrics: \n",
      " Accuracy: 79.1%, Test loss: 0.699131 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.632061  [    0/60000]\n",
      "loss: 0.765024  [ 6400/60000]\n",
      "loss: 0.559426  [12800/60000]\n",
      "loss: 0.621110  [19200/60000]\n",
      "loss: 0.502356  [25600/60000]\n",
      "loss: 0.479933  [32000/60000]\n",
      "loss: 0.449219  [38400/60000]\n",
      "loss: 0.699116  [44800/60000]\n",
      "loss: 0.629618  [51200/60000]\n",
      "loss: 0.587464  [57600/60000]\n",
      "Test Metrics: \n",
      " Accuracy: 81.4%, Test loss: 0.519512 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.428323  [    0/60000]\n",
      "loss: 0.519282  [ 6400/60000]\n",
      "loss: 0.333367  [12800/60000]\n",
      "loss: 0.560749  [19200/60000]\n",
      "loss: 0.424738  [25600/60000]\n",
      "loss: 0.478369  [32000/60000]\n",
      "loss: 0.475470  [38400/60000]\n",
      "loss: 0.724683  [44800/60000]\n",
      "loss: 0.581140  [51200/60000]\n",
      "loss: 0.489627  [57600/60000]\n",
      "Test Metrics: \n",
      " Accuracy: 82.4%, Test loss: 0.503746 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.386412  [    0/60000]\n",
      "loss: 0.490432  [ 6400/60000]\n",
      "loss: 0.358581  [12800/60000]\n",
      "loss: 0.546033  [19200/60000]\n",
      "loss: 0.377869  [25600/60000]\n",
      "loss: 0.433552  [32000/60000]\n",
      "loss: 0.392033  [38400/60000]\n",
      "loss: 0.637074  [44800/60000]\n",
      "loss: 0.607081  [51200/60000]\n",
      "loss: 0.485615  [57600/60000]\n",
      "Test Metrics: \n",
      " Accuracy: 82.8%, Test loss: 0.490056 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.342366  [    0/60000]\n",
      "loss: 0.479082  [ 6400/60000]\n",
      "loss: 0.316287  [12800/60000]\n",
      "loss: 0.493130  [19200/60000]\n",
      "loss: 0.432353  [25600/60000]\n",
      "loss: 0.430420  [32000/60000]\n",
      "loss: 0.406115  [38400/60000]\n",
      "loss: 0.674914  [44800/60000]\n",
      "loss: 0.611358  [51200/60000]\n",
      "loss: 0.458151  [57600/60000]\n",
      "Test Metrics: \n",
      " Accuracy: 83.2%, Test loss: 0.479484 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.286518  [    0/60000]\n",
      "loss: 0.461900  [ 6400/60000]\n",
      "loss: 0.294902  [12800/60000]\n",
      "loss: 0.487616  [19200/60000]\n",
      "loss: 0.449277  [25600/60000]\n",
      "loss: 0.408421  [32000/60000]\n",
      "loss: 0.408219  [38400/60000]\n",
      "loss: 0.704237  [44800/60000]\n",
      "loss: 0.582713  [51200/60000]\n",
      "loss: 0.516423  [57600/60000]\n",
      "Test Metrics: \n",
      " Accuracy: 83.6%, Test loss: 0.471353 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.265691  [    0/60000]\n",
      "loss: 0.490265  [ 6400/60000]\n",
      "loss: 0.329965  [12800/60000]\n",
      "loss: 0.524340  [19200/60000]\n",
      "loss: 0.396321  [25600/60000]\n",
      "loss: 0.411616  [32000/60000]\n",
      "loss: 0.384835  [38400/60000]\n",
      "loss: 0.623226  [44800/60000]\n",
      "loss: 0.542864  [51200/60000]\n",
      "loss: 0.464882  [57600/60000]\n",
      "Test Metrics: \n",
      " Accuracy: 84.0%, Test loss: 0.460475 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.305475  [    0/60000]\n",
      "loss: 0.453353  [ 6400/60000]\n",
      "loss: 0.288108  [12800/60000]\n",
      "loss: 0.492388  [19200/60000]\n",
      "loss: 0.370593  [25600/60000]\n",
      "loss: 0.366279  [32000/60000]\n",
      "loss: 0.411488  [38400/60000]\n",
      "loss: 0.700313  [44800/60000]\n",
      "loss: 0.557122  [51200/60000]\n",
      "loss: 0.501861  [57600/60000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Calling run.save without any arguments is deprecated.Changes to attributes are automatically persisted.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Metrics: \n",
      " Accuracy: 84.1%, Test loss: 0.458564 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 23252<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "191e91cf22054439ae89296846c49535",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>c:\\Users\\markg\\Documents\\PROGRAMMING\\PYTHON_PROJECTS\\TORCH\\DEMO_WINE_WANDB\\wandb\\run-20210710_151157-32shoccg\\logs\\debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>c:\\Users\\markg\\Documents\\PROGRAMMING\\PYTHON_PROJECTS\\TORCH\\DEMO_WINE_WANDB\\wandb\\run-20210710_151157-32shoccg\\logs\\debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>Accuracy</td><td>0.8414</td></tr><tr><td>Loss</td><td>0.45856</td></tr><tr><td>_runtime</td><td>109</td></tr><tr><td>_timestamp</td><td>1625919226</td></tr><tr><td>_step</td><td>9</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>Accuracy</td><td>▁▂▃▅▆▇▇▇██</td></tr><tr><td>Loss</td><td>█▇▆▂▂▂▁▁▁▁</td></tr><tr><td>_runtime</td><td>▁▂▂▃▄▅▆▆▇█</td></tr><tr><td>_timestamp</td><td>▁▂▂▃▄▅▆▆▇█</td></tr><tr><td>_step</td><td>▁▂▃▃▄▅▆▆▇█</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">dulcet-lion-6</strong>: <a href=\"https://wandb.ai/markgich/demo_wandb_fashionmnsit_test/runs/32shoccg\" target=\"_blank\">https://wandb.ai/markgich/demo_wandb_fashionmnsit_test/runs/32shoccg</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n",
      "Wall time: 1min 53s\n"
     ]
    }
   ],
   "source": [
    "%%time\r\n",
    "\r\n",
    "with wandb.init(project=\"demo_wandb_fashionmnsit_test\", config=config):\r\n",
    "    wandb.watch(model, criterion=loss_fn, log=\"all\", log_freq=10)\r\n",
    "    epochs = 10\r\n",
    "    for t in range(epochs):\r\n",
    "\r\n",
    "        print(f\"Epoch {t+1}\\n-------------------------------\")\r\n",
    "        train_loop(train_dataloader, model, loss_fn, optimizer)\r\n",
    "        test_loop(test_dataloader, model, loss_fn)\r\n",
    "    wandb.save(torch.save(model.state_dict(), f=f\"./models/fashion_mnist_{t}.pt\"))\r\n",
    "print(\"Done!\")\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "778de6fd147bda85163a324ce7339acfc1c656b45f8b8593316159881a238432"
  },
  "kernelspec": {
   "display_name": "Python 3.8.6 64-bit ('torch-venv': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}